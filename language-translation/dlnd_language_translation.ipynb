{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 语言翻译\n",
    "\n",
    "在此项目中，你将了解神经网络机器翻译这一领域。你将用由英语和法语语句组成的数据集，训练一个序列到序列模型（sequence to sequence model），该模型能够将新的英语句子翻译成法语。\n",
    "\n",
    "## 获取数据\n",
    "\n",
    "因为将整个英语语言内容翻译成法语需要大量训练时间，所以我们提供了一小部分的英语语料库。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import helper\n",
    "import problem_unittests as tests\n",
    "\n",
    "source_path = 'data/small_vocab_en'\n",
    "target_path = 'data/small_vocab_fr'\n",
    "source_text = helper.load_data(source_path)\n",
    "target_text = helper.load_data(target_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 探索数据\n",
    "\n",
    "研究 view_sentence_range，查看并熟悉该数据的不同部分。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Stats\n",
      "Roughly the number of unique words: 227\n",
      "Number of sentences: 137861\n",
      "Average number of words in a sentence: 13.225277634719028\n",
      "\n",
      "English sentences 0 to 10:\n",
      "new jersey is sometimes quiet during autumn , and it is snowy in april .\n",
      "the united states is usually chilly during july , and it is usually freezing in november .\n",
      "california is usually quiet during march , and it is usually hot in june .\n",
      "the united states is sometimes mild during june , and it is cold in september .\n",
      "your least liked fruit is the grape , but my least liked is the apple .\n",
      "his favorite fruit is the orange , but my favorite is the grape .\n",
      "paris is relaxing during december , but it is usually chilly in july .\n",
      "new jersey is busy during spring , and it is never hot in march .\n",
      "our least liked fruit is the lemon , but my least liked is the grape .\n",
      "the united states is sometimes busy during january , and it is sometimes warm in november .\n",
      "\n",
      "French sentences 0 to 10:\n",
      "new jersey est parfois calme pendant l' automne , et il est neigeux en avril .\n",
      "les états-unis est généralement froid en juillet , et il gèle habituellement en novembre .\n",
      "california est généralement calme en mars , et il est généralement chaud en juin .\n",
      "les états-unis est parfois légère en juin , et il fait froid en septembre .\n",
      "votre moins aimé fruit est le raisin , mais mon moins aimé est la pomme .\n",
      "son fruit préféré est l'orange , mais mon préféré est le raisin .\n",
      "paris est relaxant en décembre , mais il est généralement froid en juillet .\n",
      "new jersey est occupé au printemps , et il est jamais chaude en mars .\n",
      "notre fruit est moins aimé le citron , mais mon moins aimé est le raisin .\n",
      "les états-unis est parfois occupé en janvier , et il est parfois chaud en novembre .\n"
     ]
    }
   ],
   "source": [
    "view_sentence_range = (0, 10)\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "\n",
    "print('Dataset Stats')\n",
    "print('Roughly the number of unique words: {}'.format(len({word: None for word in source_text.split()})))\n",
    "\n",
    "sentences = source_text.split('\\n')\n",
    "word_counts = [len(sentence.split()) for sentence in sentences]\n",
    "print('Number of sentences: {}'.format(len(sentences)))\n",
    "print('Average number of words in a sentence: {}'.format(np.average(word_counts)))\n",
    "\n",
    "print()\n",
    "print('English sentences {} to {}:'.format(*view_sentence_range))\n",
    "print('\\n'.join(source_text.split('\\n')[view_sentence_range[0]:view_sentence_range[1]]))\n",
    "print()\n",
    "print('French sentences {} to {}:'.format(*view_sentence_range))\n",
    "print('\\n'.join(target_text.split('\\n')[view_sentence_range[0]:view_sentence_range[1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实现预处理函数\n",
    "\n",
    "### 文本到单词 id\n",
    "\n",
    "和之前的 RNN 一样，你必须首先将文本转换为数字，这样计算机才能读懂。在函数 `text_to_ids()` 中，你需要将单词中的 `source_text` 和 `target_text` 转为 id。但是，你需要在 `target_text` 中每个句子的末尾，添加 `<EOS>` 单词 id。这样可以帮助神经网络预测句子应该在什么地方结束。\n",
    "\n",
    "\n",
    "你可以通过以下代码获取  `<EOS> ` 单词ID：\n",
    "\n",
    "```python\n",
    "target_vocab_to_int['<EOS>']\n",
    "```\n",
    "\n",
    "你可以使用 `source_vocab_to_int` 和 `target_vocab_to_int` 获得其他单词 id。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def text_to_ids(source_text, target_text, source_vocab_to_int, target_vocab_to_int):\n",
    "    \"\"\"\n",
    "    Convert source and target text to proper word ids\n",
    "    :param source_text: String that contains all the source text.\n",
    "    :param target_text: String that contains all the target text.\n",
    "    :param source_vocab_to_int: Dictionary to go from the source words to an id\n",
    "    :param target_vocab_to_int: Dictionary to go from the target words to an id\n",
    "    :return: A tuple of lists (source_id_text, target_id_text)\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    sentences = source_text.split('\\n')\n",
    "    source_id_text = [[source_vocab_to_int[word] for word in sentence.split()] for sentence in sentences]\n",
    "    sentences = target_text.split('\\n')\n",
    "    target_id_text = [[target_vocab_to_int[word] for word in (sentence+' <EOS>').split()] for sentence in sentences]\n",
    "    return source_id_text, target_id_text\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_text_to_ids(text_to_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 预处理所有数据并保存\n",
    "\n",
    "运行以下代码单元，预处理所有数据，并保存到文件中。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "helper.preprocess_and_save_data(source_path, target_path, text_to_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 检查点\n",
    "\n",
    "这是你的第一个检查点。如果你什么时候决定再回到该记事本，或需要重新启动该记事本，可以从这里继续。预处理的数据已保存到磁盘上。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import helper\n",
    "\n",
    "# source_int_text 是一些句子的list，比如[[2, 54, 23 ...], [43, 3, 55...], ......]，target_int_text也一样\n",
    "(source_int_text, target_int_text), (source_vocab_to_int, target_vocab_to_int), _ = helper.load_preprocess()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 检查 TensorFlow 版本，确认可访问 GPU\n",
    "\n",
    "这一检查步骤，可以确保你使用的是正确版本的 TensorFlow，并且能够访问 GPU。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 1.0.1\n",
      "Default GPU Device: /gpu:0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "from distutils.version import LooseVersion\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "\n",
    "# Check TensorFlow Version\n",
    "assert LooseVersion(tf.__version__) in [LooseVersion('1.0.0'), LooseVersion('1.0.1')], 'This project requires TensorFlow version 1.0  You are using {}'.format(tf.__version__)\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))\n",
    "\n",
    "# Check for a GPU\n",
    "if not tf.test.gpu_device_name():\n",
    "    warnings.warn('No GPU found. Please use a GPU to train your neural network.')\n",
    "else:\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建神经网络\n",
    "\n",
    "你将通过实现以下函数，构建出要构建一个序列到序列模型所需的组件：\n",
    "\n",
    "- `model_inputs`\n",
    "- `process_decoding_input`\n",
    "- `encoding_layer`\n",
    "- `decoding_layer_train`\n",
    "- `decoding_layer_infer`\n",
    "- `decoding_layer`\n",
    "- `seq2seq_model`\n",
    "\n",
    "### 输入\n",
    "\n",
    "实现 `model_inputs()` 函数，为神经网络创建 TF 占位符。该函数应该创建以下占位符：\n",
    "\n",
    "- 名为 “input” 的输入文本占位符，并使用 TF Placeholder 名称参数（等级（Rank）为 2）。\n",
    "- 目标占位符（等级为 2）。\n",
    "- 学习速率占位符（等级为 0）。\n",
    "- 名为 “keep_prob” 的保留率占位符，并使用 TF Placeholder 名称参数（等级为 0）。\n",
    "\n",
    "在以下元祖（tuple）中返回占位符：（输入、目标、学习速率、保留率）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def model_inputs():\n",
    "    \"\"\"\n",
    "    Create TF Placeholders for input, targets, and learning rate.\n",
    "    :return: Tuple (input, targets, learning rate, keep probability)\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    input = tf.placeholder(tf.int32, shape=(None, None), name='input')\n",
    "    output = tf.placeholder(tf.int32, shape=(None, None), name='output')\n",
    "    learning_rate = tf.placeholder(tf.float32, shape=None, name='learning_rate')\n",
    "    keep_prob = tf.placeholder(tf.float32, shape=None, name='keep_prob')\n",
    "    return input, output, learning_rate, keep_prob\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_model_inputs(model_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 处理解码输入\n",
    "\n",
    "使用 TensorFlow 实现 `process_decoding_input`，以便删掉 `target_data` 中每个批次的最后一个单词 ID，并将 GO ID 放到每个批次的开头。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "# 训练时，在序列的解码部分，将正确的word（来自target）作为模型的输入序列，而不是用model预测的word作为输入\n",
    "def process_decoding_input(target_data, target_vocab_to_int, batch_size):\n",
    "    \"\"\"\n",
    "    Preprocess target data for dencoding\n",
    "    :param target_data: Target Placehoder\n",
    "    :param target_vocab_to_int: Dictionary to go from the target words to an id\n",
    "    :param batch_size: Batch Size\n",
    "    :return: Preprocessed target data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    go_array = tf.fill((batch_size,1), target_vocab_to_int['<GO>'])\n",
    "#    print(go_array)\n",
    "    target_data = tf.concat([go_array, target_data], 1)\n",
    "#    print(target_data)\n",
    "#    target_data = tf.slice(target_data, [0,0], [batch_size, -1])\n",
    "    target_data = target_data[:,0:-1]\n",
    "#    print(target_data)\n",
    "    return target_data\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_process_decoding_input(process_decoding_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 编码\n",
    "\n",
    "实现 `encoding_layer()`，以使用 [`tf.nn.dynamic_rnn()`](https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn) 创建编码器 RNN 层级。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "# 序列到序列模型的编码部分的LSTM\n",
    "def encoding_layer(rnn_inputs, rnn_size, num_layers, keep_prob):\n",
    "    \"\"\"\n",
    "    Create encoding layer\n",
    "    :param rnn_inputs: Inputs for the RNN\n",
    "    :param rnn_size: RNN Size\n",
    "    :param num_layers: Number of layers\n",
    "    :param keep_prob: Dropout keep probability\n",
    "    :return: RNN state\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    cell = tf.contrib.rnn.BasicLSTMCell(num_units=rnn_size)\n",
    "    cells = tf.contrib.rnn.MultiRNNCell(num_layers * [cell])\n",
    "#    initial_state = cells.zero_state(batch_size, tf.float32)\n",
    "    outputs, state = tf.nn.dynamic_rnn(cells, rnn_inputs, dtype=tf.float32)\n",
    "#    final_state = tf.identity(final_state, name='final_state')\n",
    "    return state\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_encoding_layer(encoding_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 解码 - 训练\n",
    "\n",
    "使用 [`tf.contrib.seq2seq.simple_decoder_fn_train()`](https://www.tensorflow.org/versions/r1.0/api_docs/python/tf/contrib/seq2seq/simple_decoder_fn_train) 和 [`tf.contrib.seq2seq.dynamic_rnn_decoder()`](https://www.tensorflow.org/versions/r1.0/api_docs/python/tf/contrib/seq2seq/dynamic_rnn_decoder) 创建训练分对数（training logits）。将 `output_fn` 应用到 [`tf.contrib.seq2seq.dynamic_rnn_decoder()`](https://www.tensorflow.org/versions/r1.0/api_docs/python/tf/contrib/seq2seq/dynamic_rnn_decoder) 输出上。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "# 模型解码部分，训练时（inference）的输出\n",
    "def decoding_layer_train(encoder_state, dec_cell, dec_embed_input, sequence_length, decoding_scope,\n",
    "                         output_fn, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a decoding layer for training\n",
    "    :param encoder_state: Encoder State\n",
    "    :param dec_cell: Decoder RNN Cell\n",
    "    :param dec_embed_input: Decoder embedded input\n",
    "    :param sequence_length: Sequence Length\n",
    "    :param decoding_scope: TenorFlow Variable Scope for decoding\n",
    "    :param output_fn: Function to apply the output layer\n",
    "    :param keep_prob: Dropout keep probability\n",
    "    :return: Train Logits\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    dynamic_fn_train = tf.contrib.seq2seq.simple_decoder_fn_train(encoder_state)\n",
    "    outputs_train, _, _ = tf.contrib.seq2seq.dynamic_rnn_decoder(dec_cell, dynamic_fn_train, inputs=dec_embed_input, sequence_length=sequence_length, scope=decoding_scope)\n",
    "#    print('outputs_train.get_shape()', outputs_train.get_shape())\n",
    "    outputs_train = tf.nn.dropout(outputs_train, keep_prob)\n",
    "    outputs_train = output_fn(outputs_train)\n",
    "#    print('outputs_train.get_shape()', outputs_train.get_shape())\n",
    "    return outputs_train\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_decoding_layer_train(decoding_layer_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 解码 - 推论\n",
    "\n",
    "使用 [`tf.contrib.seq2seq.simple_decoder_fn_inference()`](https://www.tensorflow.org/versions/r1.0/api_docs/python/tf/contrib/seq2seq/simple_decoder_fn_inference) 和 [`tf.contrib.seq2seq.dynamic_rnn_decoder()`](https://www.tensorflow.org/versions/r1.0/api_docs/python/tf/contrib/seq2seq/dynamic_rnn_decoder) 创建推论分对数（inference logits）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "# 模型解码部分，预测时（inference）的输出。预测阶段keep_prob应无必要。\n",
    "def decoding_layer_infer(encoder_state, dec_cell, dec_embeddings, start_of_sequence_id, end_of_sequence_id,\n",
    "                         maximum_length, vocab_size, decoding_scope, output_fn, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a decoding layer for inference\n",
    "    :param encoder_state: Encoder state\n",
    "    :param dec_cell: Decoder RNN Cell\n",
    "    :param dec_embeddings: Decoder embeddings\n",
    "    :param start_of_sequence_id: GO ID\n",
    "    :param end_of_sequence_id: EOS Id\n",
    "    :param maximum_length: The maximum allowed time steps to decode\n",
    "    :param vocab_size: Size of vocabulary\n",
    "    :param decoding_scope: TensorFlow Variable Scope for decoding\n",
    "    :param output_fn: Function to apply the output layer\n",
    "    :param keep_prob: Dropout keep probability\n",
    "    :return: Inference Logits\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    dynamic_fn_infer = tf.contrib.seq2seq.simple_decoder_fn_inference(output_fn, encoder_state, dec_embeddings, start_of_sequence_id, end_of_sequence_id, maximum_length, vocab_size)\n",
    "    outputs_infer, _, _ = tf.contrib.seq2seq.dynamic_rnn_decoder(dec_cell, dynamic_fn_infer, scope=decoding_scope)\n",
    "#    print('outputs_infer.get_shape()', outputs_infer.get_shape())\n",
    "#    outputs_infer = tf.nn.dropout(outputs_infer, keep_prob)\n",
    "#    print('outputs_infer.get_shape()', outputs_infer.get_shape())\n",
    "#    outputs_infer = output_fn(outputs_infer)\n",
    "#    print('outputs_infer.get_shape()', outputs_infer.get_shape())\n",
    "    return outputs_infer\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_decoding_layer_infer(decoding_layer_infer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构建解码层级\n",
    "\n",
    "实现 `decoding_layer()` 以创建解码器 RNN 层级。\n",
    "\n",
    "- 使用 `rnn_size` 和 `num_layers` 创建解码 RNN 单元。\n",
    "- 使用 [`lambda`](https://docs.python.org/3/tutorial/controlflow.html#lambda-expressions) 创建输出函数，将输入，也就是分对数转换为类分对数（class logits）。\n",
    "- 使用 `decoding_layer_train(encoder_state, dec_cell, dec_embed_input, sequence_length, decoding_scope, output_fn, keep_prob)` 函数获取训练分对数。\n",
    "- 使用 `decoding_layer_infer(encoder_state, dec_cell, dec_embeddings, start_of_sequence_id, end_of_sequence_id, maximum_length, vocab_size, decoding_scope, output_fn, keep_prob)` 函数获取推论分对数。\n",
    "\n",
    "注意：你将需要使用 [tf.variable_scope](https://www.tensorflow.org/api_docs/python/tf/variable_scope) 在训练和推论分对数间分享变量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "# 模型的解码部分。包括训练时解码和预测时解码的输出\n",
    "def decoding_layer(dec_embed_input, dec_embeddings, encoder_state, vocab_size, sequence_length, rnn_size,\n",
    "                   num_layers, target_vocab_to_int, keep_prob):\n",
    "    \"\"\"\n",
    "    Create decoding layer\n",
    "    :param dec_embed_input: Decoder embedded input。已经经过embedding矩阵转换后的编码，shape=(batch_size, sequence_length, embedding_size)\n",
    "    :param dec_embeddings: Decoder embeddings。embedding转换矩阵，shape=(vocab_size, embedding_size)\n",
    "    :param encoder_state: The encoded state\n",
    "    :param vocab_size: Size of vocabulary\n",
    "    :param sequence_length: Sequence Length\n",
    "    :param rnn_size: RNN Size\n",
    "    :param num_layers: Number of layers\n",
    "    :param target_vocab_to_int: Dictionary to go from the target words to an id\n",
    "    :param keep_prob: Dropout keep probability\n",
    "    :return: Tuple of (Training Logits, Inference Logits)\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    with tf.variable_scope(\"decoding\") as decoding_scope:\n",
    "        # 模型解码部分的LSTM\n",
    "        cell = tf.contrib.rnn.BasicLSTMCell(num_units=rnn_size)\n",
    "        cells = tf.contrib.rnn.MultiRNNCell(num_layers * [cell])\n",
    "    #    outputs, state = tf.nn.dynamic_rnn(cells, dec_embed_output, dtype=tf.float32)\n",
    "    \n",
    "        # LSTM输出接入全连接层（rnn_size向量转换为vocab_size向量）\n",
    "        output_fn = lambda x: tf.contrib.layers.fully_connected(x, vocab_size, None, scope=decoding_scope)\n",
    "        \n",
    "        # 模型解码部分，训练时的输出序列（用target作为输入）\n",
    "        outputs_train = decoding_layer_train(encoder_state, cells, dec_embed_input, sequence_length, decoding_scope,\n",
    "                                             output_fn, keep_prob)\n",
    "        # \n",
    "        decoding_scope.reuse_variables()\n",
    "        # 模型解码部分，预测时(inference)的输出序列（用上一个时间步的输出作为输入）\n",
    "        outputs_infer = decoding_layer_infer(encoder_state, cells, dec_embeddings, \n",
    "                                             target_vocab_to_int['<GO>'], target_vocab_to_int['<EOS>'],\n",
    "                                             sequence_length, vocab_size, decoding_scope, output_fn, keep_prob)\n",
    "    return outputs_train, outputs_infer\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_decoding_layer(decoding_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构建神经网络\n",
    "\n",
    "应用你在上方实现的函数，以：\n",
    "\n",
    "- 向编码器的输入数据应用嵌入。\n",
    "- 使用 `encoding_layer(rnn_inputs, rnn_size, num_layers, keep_prob)` 编码输入。\n",
    "- 使用 `process_decoding_input(target_data, target_vocab_to_int, batch_size)` 函数处理目标数据。\n",
    "- 向解码器的目标数据应用嵌入。\n",
    "- 使用 `decoding_layer(dec_embed_input, dec_embeddings, encoder_state, vocab_size, sequence_length, rnn_size, num_layers, target_vocab_to_int, keep_prob)` 解码编码的输入数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "# 序列到序列模型\n",
    "def seq2seq_model(input_data, target_data, keep_prob, batch_size, sequence_length, source_vocab_size, target_vocab_size,\n",
    "                  enc_embedding_size, dec_embedding_size, rnn_size, num_layers, target_vocab_to_int):\n",
    "    \"\"\"\n",
    "    Build the Sequence-to-Sequence part of the neural network\n",
    "    :param input_data: Input placeholder。shape=(batch_size, sequence_length)\n",
    "    :param target_data: Target placeholder\n",
    "    :param keep_prob: Dropout keep probability placeholder\n",
    "    :param batch_size: Batch Size\n",
    "    :param sequence_length: Sequence Length\n",
    "    :param source_vocab_size: Source vocabulary size\n",
    "    :param target_vocab_size: Target vocabulary size\n",
    "    :param enc_embedding_size: Decoder embedding size\n",
    "    :param dec_embedding_size: Encoder embedding size\n",
    "    :param rnn_size: RNN Size\n",
    "    :param num_layers: Number of layers\n",
    "    :param target_vocab_to_int: Dictionary to go from the target words to an id\n",
    "    :return: Tuple of (Training Logits, Inference Logits)\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    # 编码部分和解码部分的embedding转换矩阵\n",
    "    embedding_enc = tf.Variable(tf.truncated_normal(shape=[source_vocab_size, enc_embedding_size], mean=0, stddev=1)) # create embedding weight matrix here\n",
    "    embedding_dec = tf.Variable(tf.truncated_normal(shape=[target_vocab_size, dec_embedding_size], mean=0, stddev=1)) # create embedding weight matrix here\n",
    "\n",
    "    # input_data进行embed编码\n",
    "    input_data_embed = tf.nn.embedding_lookup(embedding_enc, input_data)\n",
    "\n",
    "    # 模型的编码部分（处理输入序列）\n",
    "    encoder_state = encoding_layer(input_data_embed, rnn_size, num_layers, keep_prob)\n",
    "    \n",
    "    # 模型的解码部分，先将target_data转换成解码部分的输入\n",
    "    dec_input = process_decoding_input(target_data, target_vocab_to_int, batch_size)\n",
    "    # dec_input进行embed编码\n",
    "    dec_embed_input = tf.nn.embedding_lookup(embedding_dec, dec_input)\n",
    "    \n",
    "    # 模型的解码部分（处理输出序列）\n",
    "    outputs_train, outputs_infer = decoding_layer(dec_embed_input, embedding_dec, encoder_state, \n",
    "            target_vocab_size, sequence_length, rnn_size, num_layers, target_vocab_to_int, keep_prob)\n",
    "    \n",
    "    return outputs_train, outputs_infer\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_seq2seq_model(seq2seq_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练神经网络\n",
    "\n",
    "### 超参数\n",
    "\n",
    "调试以下参数：\n",
    "\n",
    "- 将 `epochs` 设为 epoch 次数。\n",
    "- 将 `batch_size` 设为批次大小。\n",
    "- 将 `rnn_size` 设为 RNN 的大小。\n",
    "- 将 `num_layers` 设为层级数量。\n",
    "- 将 `encoding_embedding_size` 设为编码器嵌入大小。\n",
    "- 将 `decoding_embedding_size` 设为解码器嵌入大小\n",
    "- 将 `learning_rate` 设为训练速率。\n",
    "- 将 `keep_probability` 设为丢弃保留率（Dropout keep probability）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Number of Epochs\n",
    "epochs = 10\n",
    "# Batch Size\n",
    "batch_size = 1024\n",
    "# RNN Size\n",
    "rnn_size = 64\n",
    "# Number of Layers\n",
    "num_layers = 3\n",
    "# Embedding Size\n",
    "encoding_embedding_size = 200\n",
    "decoding_embedding_size = 200\n",
    "# Learning Rate\n",
    "learning_rate = 0.02\n",
    "# Dropout Keep Probability\n",
    "keep_probability = 0.6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构建图表\n",
    "\n",
    "使用你实现的神经网络构建图表。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "save_path = 'checkpoints/dev'\n",
    "(source_int_text, target_int_text), (source_vocab_to_int, target_vocab_to_int), _ = helper.load_preprocess()\n",
    "max_source_sentence_length = max([len(sentence) for sentence in source_int_text])\n",
    "\n",
    "train_graph = tf.Graph()\n",
    "with train_graph.as_default():\n",
    "    input_data, targets, lr, keep_prob = model_inputs()\n",
    "    sequence_length = tf.placeholder_with_default(max_source_sentence_length, None, name='sequence_length')\n",
    "    input_shape = tf.shape(input_data)\n",
    "    \n",
    "    train_logits, inference_logits = seq2seq_model(\n",
    "        tf.reverse(input_data, [-1]), targets, keep_prob, batch_size, sequence_length, len(source_vocab_to_int), len(target_vocab_to_int),\n",
    "        encoding_embedding_size, decoding_embedding_size, rnn_size, num_layers, target_vocab_to_int)\n",
    "\n",
    "    tf.identity(inference_logits, 'logits')\n",
    "    with tf.name_scope(\"optimization\"):\n",
    "        # Loss function\n",
    "        cost = tf.contrib.seq2seq.sequence_loss(\n",
    "            train_logits,\n",
    "            targets,\n",
    "            tf.ones([input_shape[0], sequence_length]))\n",
    "\n",
    "        # Optimizer\n",
    "        optimizer = tf.train.AdamOptimizer(lr)\n",
    "\n",
    "        # Gradient Clipping\n",
    "        gradients = optimizer.compute_gradients(cost)\n",
    "        capped_gradients = [(tf.clip_by_value(grad, -1., 1.), var) for grad, var in gradients if grad is not None]\n",
    "        train_op = optimizer.apply_gradients(capped_gradients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练\n",
    "\n",
    "利用预处理的数据训练神经网络。如果很难获得低损失值，请访问我们的论坛，看看其他人是否遇到了相同的问题。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 Batch    0/134 - Train Accuracy:  0.297, Validation Accuracy:  0.339, Loss:  5.873\n",
      "Epoch   0 Batch   20/134 - Train Accuracy:  0.368, Validation Accuracy:  0.371, Loss:  2.663\n",
      "Epoch   0 Batch   40/134 - Train Accuracy:  0.438, Validation Accuracy:  0.464, Loss:  2.182\n",
      "Epoch   0 Batch   60/134 - Train Accuracy:  0.431, Validation Accuracy:  0.463, Loss:  1.838\n",
      "Epoch   0 Batch   80/134 - Train Accuracy:  0.453, Validation Accuracy:  0.482, Loss:  1.582\n",
      "Epoch   0 Batch  100/134 - Train Accuracy:  0.484, Validation Accuracy:  0.507, Loss:  1.312\n",
      "Epoch   0 Batch  120/134 - Train Accuracy:  0.512, Validation Accuracy:  0.534, Loss:  1.081\n",
      "Epoch   1 Batch    0/134 - Train Accuracy:  0.570, Validation Accuracy:  0.589, Loss:  0.962\n",
      "Epoch   1 Batch   20/134 - Train Accuracy:  0.630, Validation Accuracy:  0.634, Loss:  0.798\n",
      "Epoch   1 Batch   40/134 - Train Accuracy:  0.646, Validation Accuracy:  0.648, Loss:  0.737\n",
      "Epoch   1 Batch   60/134 - Train Accuracy:  0.659, Validation Accuracy:  0.665, Loss:  0.667\n",
      "Epoch   1 Batch   80/134 - Train Accuracy:  0.651, Validation Accuracy:  0.661, Loss:  0.672\n",
      "Epoch   1 Batch  100/134 - Train Accuracy:  0.667, Validation Accuracy:  0.678, Loss:  0.595\n",
      "Epoch   1 Batch  120/134 - Train Accuracy:  0.686, Validation Accuracy:  0.694, Loss:  0.555\n",
      "Epoch   2 Batch    0/134 - Train Accuracy:  0.714, Validation Accuracy:  0.709, Loss:  0.526\n",
      "Epoch   2 Batch   20/134 - Train Accuracy:  0.741, Validation Accuracy:  0.724, Loss:  0.466\n",
      "Epoch   2 Batch   40/134 - Train Accuracy:  0.732, Validation Accuracy:  0.728, Loss:  0.447\n",
      "Epoch   2 Batch   60/134 - Train Accuracy:  0.752, Validation Accuracy:  0.750, Loss:  0.408\n",
      "Epoch   2 Batch   80/134 - Train Accuracy:  0.760, Validation Accuracy:  0.766, Loss:  0.386\n",
      "Epoch   2 Batch  100/134 - Train Accuracy:  0.766, Validation Accuracy:  0.772, Loss:  0.356\n",
      "Epoch   2 Batch  120/134 - Train Accuracy:  0.767, Validation Accuracy:  0.763, Loss:  0.338\n",
      "Epoch   3 Batch    0/134 - Train Accuracy:  0.780, Validation Accuracy:  0.784, Loss:  0.323\n",
      "Epoch   3 Batch   20/134 - Train Accuracy:  0.801, Validation Accuracy:  0.791, Loss:  0.293\n",
      "Epoch   3 Batch   40/134 - Train Accuracy:  0.801, Validation Accuracy:  0.796, Loss:  0.292\n",
      "Epoch   3 Batch   60/134 - Train Accuracy:  0.796, Validation Accuracy:  0.797, Loss:  0.271\n",
      "Epoch   3 Batch   80/134 - Train Accuracy:  0.801, Validation Accuracy:  0.808, Loss:  0.258\n",
      "Epoch   3 Batch  100/134 - Train Accuracy:  0.800, Validation Accuracy:  0.811, Loss:  0.243\n",
      "Epoch   3 Batch  120/134 - Train Accuracy:  0.792, Validation Accuracy:  0.792, Loss:  0.234\n",
      "Epoch   4 Batch    0/134 - Train Accuracy:  0.819, Validation Accuracy:  0.812, Loss:  0.235\n",
      "Epoch   4 Batch   20/134 - Train Accuracy:  0.829, Validation Accuracy:  0.819, Loss:  0.208\n",
      "Epoch   4 Batch   40/134 - Train Accuracy:  0.814, Validation Accuracy:  0.816, Loss:  0.213\n",
      "Epoch   4 Batch   60/134 - Train Accuracy:  0.819, Validation Accuracy:  0.824, Loss:  0.195\n",
      "Epoch   4 Batch   80/134 - Train Accuracy:  0.828, Validation Accuracy:  0.842, Loss:  0.195\n",
      "Epoch   4 Batch  100/134 - Train Accuracy:  0.824, Validation Accuracy:  0.831, Loss:  0.188\n",
      "Epoch   4 Batch  120/134 - Train Accuracy:  0.823, Validation Accuracy:  0.834, Loss:  0.181\n",
      "Epoch   5 Batch    0/134 - Train Accuracy:  0.833, Validation Accuracy:  0.833, Loss:  0.176\n",
      "Epoch   5 Batch   20/134 - Train Accuracy:  0.848, Validation Accuracy:  0.842, Loss:  0.164\n",
      "Epoch   5 Batch   40/134 - Train Accuracy:  0.831, Validation Accuracy:  0.848, Loss:  0.172\n",
      "Epoch   5 Batch   60/134 - Train Accuracy:  0.836, Validation Accuracy:  0.847, Loss:  0.160\n",
      "Epoch   5 Batch   80/134 - Train Accuracy:  0.838, Validation Accuracy:  0.853, Loss:  0.159\n",
      "Epoch   5 Batch  100/134 - Train Accuracy:  0.836, Validation Accuracy:  0.852, Loss:  0.151\n",
      "Epoch   5 Batch  120/134 - Train Accuracy:  0.846, Validation Accuracy:  0.853, Loss:  0.147\n",
      "Epoch   6 Batch    0/134 - Train Accuracy:  0.857, Validation Accuracy:  0.855, Loss:  0.141\n",
      "Epoch   6 Batch   20/134 - Train Accuracy:  0.867, Validation Accuracy:  0.856, Loss:  0.135\n",
      "Epoch   6 Batch   40/134 - Train Accuracy:  0.853, Validation Accuracy:  0.865, Loss:  0.140\n",
      "Epoch   6 Batch   60/134 - Train Accuracy:  0.860, Validation Accuracy:  0.858, Loss:  0.128\n",
      "Epoch   6 Batch   80/134 - Train Accuracy:  0.862, Validation Accuracy:  0.871, Loss:  0.126\n",
      "Epoch   6 Batch  100/134 - Train Accuracy:  0.876, Validation Accuracy:  0.873, Loss:  0.125\n",
      "Epoch   6 Batch  120/134 - Train Accuracy:  0.876, Validation Accuracy:  0.874, Loss:  0.124\n",
      "Epoch   7 Batch    0/134 - Train Accuracy:  0.882, Validation Accuracy:  0.876, Loss:  0.119\n",
      "Epoch   7 Batch   20/134 - Train Accuracy:  0.889, Validation Accuracy:  0.895, Loss:  0.114\n",
      "Epoch   7 Batch   40/134 - Train Accuracy:  0.882, Validation Accuracy:  0.887, Loss:  0.113\n",
      "Epoch   7 Batch   60/134 - Train Accuracy:  0.893, Validation Accuracy:  0.907, Loss:  0.109\n",
      "Epoch   7 Batch   80/134 - Train Accuracy:  0.912, Validation Accuracy:  0.909, Loss:  0.110\n",
      "Epoch   7 Batch  100/134 - Train Accuracy:  0.908, Validation Accuracy:  0.915, Loss:  0.107\n",
      "Epoch   7 Batch  120/134 - Train Accuracy:  0.917, Validation Accuracy:  0.921, Loss:  0.104\n",
      "Epoch   8 Batch    0/134 - Train Accuracy:  0.920, Validation Accuracy:  0.913, Loss:  0.099\n",
      "Epoch   8 Batch   20/134 - Train Accuracy:  0.911, Validation Accuracy:  0.917, Loss:  0.097\n",
      "Epoch   8 Batch   40/134 - Train Accuracy:  0.914, Validation Accuracy:  0.921, Loss:  0.098\n",
      "Epoch   8 Batch   60/134 - Train Accuracy:  0.923, Validation Accuracy:  0.924, Loss:  0.095\n",
      "Epoch   8 Batch   80/134 - Train Accuracy:  0.925, Validation Accuracy:  0.924, Loss:  0.094\n",
      "Epoch   8 Batch  100/134 - Train Accuracy:  0.924, Validation Accuracy:  0.928, Loss:  0.091\n",
      "Epoch   8 Batch  120/134 - Train Accuracy:  0.926, Validation Accuracy:  0.933, Loss:  0.095\n",
      "Epoch   9 Batch    0/134 - Train Accuracy:  0.932, Validation Accuracy:  0.922, Loss:  0.086\n",
      "Epoch   9 Batch   20/134 - Train Accuracy:  0.921, Validation Accuracy:  0.926, Loss:  0.086\n",
      "Epoch   9 Batch   40/134 - Train Accuracy:  0.925, Validation Accuracy:  0.928, Loss:  0.086\n",
      "Epoch   9 Batch   60/134 - Train Accuracy:  0.928, Validation Accuracy:  0.921, Loss:  0.079\n",
      "Epoch   9 Batch   80/134 - Train Accuracy:  0.927, Validation Accuracy:  0.927, Loss:  0.086\n",
      "Epoch   9 Batch  100/134 - Train Accuracy:  0.937, Validation Accuracy:  0.931, Loss:  0.082\n",
      "Epoch   9 Batch  120/134 - Train Accuracy:  0.927, Validation Accuracy:  0.934, Loss:  0.083\n",
      "Model Trained and Saved\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import time\n",
    "\n",
    "num_batches_to_print = 20\n",
    "num_batches_to_list = 1\n",
    "train_acc_list = list()\n",
    "valid_acc_list = list()\n",
    "train_loss_list = list()\n",
    "\n",
    "def get_accuracy(target, logits):\n",
    "    \"\"\"\n",
    "    Calculate accuracy\n",
    "    \"\"\"\n",
    "    max_seq = max(target.shape[1], logits.shape[1])\n",
    "    if max_seq - target.shape[1]:\n",
    "        target = np.pad(\n",
    "            target,\n",
    "            [(0,0),(0,max_seq - target.shape[1])],\n",
    "            'constant')\n",
    "    if max_seq - logits.shape[1]:\n",
    "        logits = np.pad(\n",
    "            logits,\n",
    "            [(0,0),(0,max_seq - logits.shape[1]), (0,0)],\n",
    "            'constant')\n",
    "\n",
    "    return np.mean(np.equal(target, np.argmax(logits, 2)))\n",
    "\n",
    "train_source = source_int_text[batch_size:]\n",
    "train_target = target_int_text[batch_size:]\n",
    "\n",
    "valid_source = helper.pad_sentence_batch(source_int_text[:batch_size])\n",
    "valid_target = helper.pad_sentence_batch(target_int_text[:batch_size])\n",
    "\n",
    "with tf.Session(graph=train_graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for epoch_i in range(epochs):\n",
    "        for batch_i, (source_batch, target_batch) in enumerate(\n",
    "                helper.batch_data(train_source, train_target, batch_size)):\n",
    "            start_time = time.time()\n",
    "            \n",
    "            _, loss = sess.run(\n",
    "                [train_op, cost],\n",
    "                {input_data: source_batch,\n",
    "                 targets: target_batch,\n",
    "                 lr: learning_rate,\n",
    "                 sequence_length: target_batch.shape[1],\n",
    "                 keep_prob: keep_probability})\n",
    "            \n",
    "            batch_train_logits = sess.run(\n",
    "                inference_logits,\n",
    "                {input_data: source_batch, keep_prob: 1.0})\n",
    "            batch_valid_logits = sess.run(\n",
    "                inference_logits,\n",
    "                {input_data: valid_source, keep_prob: 1.0})\n",
    "                \n",
    "            train_acc = get_accuracy(target_batch, batch_train_logits)\n",
    "            valid_acc = get_accuracy(np.array(valid_target), batch_valid_logits)\n",
    "            end_time = time.time()\n",
    "            \n",
    "            # 记录loss和acc\n",
    "            if batch_i % num_batches_to_list == 0:\n",
    "                train_acc_list.append(train_acc)\n",
    "                valid_acc_list.append(valid_acc)\n",
    "                train_loss_list.append(loss)\n",
    "            if batch_i % num_batches_to_print == 0:\n",
    "                print('Epoch {:>3} Batch {:>4}/{} - Train Accuracy: {:>6.3f}, Validation Accuracy: {:>6.3f}, Loss: {:>6.3f}'\n",
    "                      .format(epoch_i, batch_i, len(source_int_text) // batch_size, train_acc, valid_acc, loss))\n",
    "\n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess, save_path)\n",
    "    print('Model Trained and Saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRCTNqLhFRNKMiltEJM38F6Pr8uzaIXIRAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x23ec1f4f780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x23d420fed68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 打印loss和acc\n",
    "import matplotlib.pyplot as plt\n",
    "batch_number = list(range(len(train_acc_list)))\n",
    "plt.plot(batch_number, train_loss_list, label='train_loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.plot(batch_number, train_acc_list, label='train_acc')\n",
    "plt.plot(batch_number, valid_acc_list, label='valid_acc')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 保存参数\n",
    "\n",
    "保存 `batch_size` 和 `save_path` 参数以进行推论（for inference）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "# Save parameters for checkpoint\n",
    "helper.save_params(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 检查点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import helper\n",
    "import problem_unittests as tests\n",
    "\n",
    "_, (source_vocab_to_int, target_vocab_to_int), (source_int_to_vocab, target_int_to_vocab) = helper.load_preprocess()\n",
    "load_path = helper.load_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 句子到序列\n",
    "\n",
    "要向模型提供要翻译的句子，你首先需要预处理该句子。实现函数 `sentence_to_seq()` 以预处理新的句子。\n",
    "\n",
    "- 将句子转换为小写形式\n",
    "- 使用 `vocab_to_int` 将单词转换为 id\n",
    " - 如果单词不在词汇表中，将其转换为`<UNK>` 单词 id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def sentence_to_seq(sentence, vocab_to_int):\n",
    "    \"\"\"\n",
    "    Convert a sentence to a sequence of ids\n",
    "    :param sentence: String\n",
    "    :param vocab_to_int: Dictionary to go from the words to an id\n",
    "    :return: List of word ids\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return [vocab_to_int.get(word, vocab_to_int['<UNK>']) for word in sentence.lower().split()]\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_sentence_to_seq(sentence_to_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 翻译\n",
    "\n",
    "将 `translate_sentence` 从英语翻译成法语。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input\n",
      "  Word Ids:      [47, 91, 165, 8, 152, 160, 169]\n",
      "  English Words: ['he', 'saw', 'a', 'old', 'yellow', 'truck', '.']\n",
      "\n",
      "Prediction\n",
      "  Word Ids:      [91, 328, 92, 160, 178, 349, 307, 330, 1]\n",
      "  French Words: ['il', 'a', 'vu', 'un', 'camion', 'rouge', 'brillant', '.', '<EOS>']\n"
     ]
    }
   ],
   "source": [
    "translate_sentence = 'he saw a old yellow truck .'\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "translate_sentence = sentence_to_seq(translate_sentence, source_vocab_to_int)\n",
    "\n",
    "loaded_graph = tf.Graph()\n",
    "with tf.Session(graph=loaded_graph) as sess:\n",
    "    # Load saved model\n",
    "    loader = tf.train.import_meta_graph(load_path + '.meta')\n",
    "    loader.restore(sess, load_path)\n",
    "\n",
    "    input_data = loaded_graph.get_tensor_by_name('input:0')\n",
    "    logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "    keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "\n",
    "    translate_logits = sess.run(logits, {input_data: [translate_sentence], keep_prob: 1.0})[0]\n",
    "\n",
    "print('Input')\n",
    "print('  Word Ids:      {}'.format([i for i in translate_sentence]))\n",
    "print('  English Words: {}'.format([source_int_to_vocab[i] for i in translate_sentence]))\n",
    "\n",
    "print('\\nPrediction')\n",
    "print('  Word Ids:      {}'.format([i for i in np.argmax(translate_logits, 1)]))\n",
    "print('  French Words: {}'.format([target_int_to_vocab[i] for i in np.argmax(translate_logits, 1)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 不完美的翻译\n",
    "\n",
    "你可能注意到了，某些句子的翻译质量比其他的要好。因为你使用的数据集只有 227 个英语单词，但实际生活中有数千个单词，只有使用这些单词的句子结果才会比较理想。对于此项目，不需要达到完美的翻译。但是，如果你想创建更好的翻译模型，则需要更好的数据。\n",
    "\n",
    "你可以使用 [WMT10 French-English corpus](http://www.statmt.org/wmt10/training-giga-fren.tar) 语料库训练模型。该数据集拥有更多的词汇，讨论的话题也更丰富。但是，训练时间要好多天的时间，所以确保你有 GPU 并且对于我们提供的数据集，你的神经网络性能很棒。提交此项目后，别忘了研究下 WMT10 语料库。\n",
    "\n",
    "\n",
    "## 提交项目\n",
    "\n",
    "提交项目时，确保先运行所有单元，然后再保存记事本。保存记事本文件为 “dlnd_language_translation.ipynb”，再通过菜单中的“文件” ->“下载为”将其另存为 HTML 格式。提交的项目文档中需包含“helper.py”和“problem_unittests.py”文件。\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
