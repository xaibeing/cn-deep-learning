{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 图像分类\n",
    "\n",
    "在此项目中，你将对 [CIFAR-10 数据集](https://www.cs.toronto.edu/~kriz/cifar.html) 中的图片进行分类。该数据集包含飞机、猫狗和其他物体。你需要预处理这些图片，然后用所有样本训练一个卷积神经网络。图片需要标准化（normalized），标签需要采用 one-hot 编码。你需要应用所学的知识构建卷积的、最大池化（max pooling）、丢弃（dropout）和完全连接（fully connected）的层。最后，你需要在样本图片上看到神经网络的预测结果。\n",
    "\n",
    "\n",
    "## 获取数据\n",
    "\n",
    "请运行以下单元，以下载 [CIFAR-10 数据集（Python版）](https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz)。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files found!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "import problem_unittests as tests\n",
    "import tarfile\n",
    "\n",
    "cifar10_dataset_folder_path = 'cifar-10-batches-py'\n",
    "\n",
    "# Use Floyd's cifar-10 dataset if present\n",
    "floyd_cifar10_location = '/input/cifar-10/python.tar.gz'\n",
    "if isfile(floyd_cifar10_location):\n",
    "    tar_gz_path = floyd_cifar10_location\n",
    "else:\n",
    "    tar_gz_path = 'cifar-10-python.tar.gz'\n",
    "\n",
    "class DLProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "if not isfile(tar_gz_path):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='CIFAR-10 Dataset') as pbar:\n",
    "        urlretrieve(\n",
    "            'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz',\n",
    "            tar_gz_path,\n",
    "            pbar.hook)\n",
    "\n",
    "if not isdir(cifar10_dataset_folder_path):\n",
    "    with tarfile.open(tar_gz_path) as tar:\n",
    "        tar.extractall()\n",
    "        tar.close()\n",
    "\n",
    "\n",
    "tests.test_folder_path(cifar10_dataset_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 探索数据\n",
    "\n",
    "该数据集分成了几部分／批次（batches），以免你的机器在计算时内存不足。CIFAR-10 数据集包含 5 个部分，名称分别为 `data_batch_1`、`data_batch_2`，以此类推。每个部分都包含以下某个类别的标签和图片：\n",
    "\n",
    "* 飞机\n",
    "* 汽车\n",
    "* 鸟类\n",
    "* 猫\n",
    "* 鹿\n",
    "* 狗\n",
    "* 青蛙\n",
    "* 马\n",
    "* 船只\n",
    "* 卡车\n",
    "\n",
    "了解数据集也是对数据进行预测的必经步骤。你可以通过更改 `batch_id` 和 `sample_id` 探索下面的代码单元。`batch_id` 是数据集一个部分的 ID（1 到 5）。`sample_id` 是该部分中图片和标签对（label pair）的 ID。\n",
    "\n",
    "问问你自己：“可能的标签有哪些？”、“图片数据的值范围是多少？”、“标签是按顺序排列，还是随机排列的？”。思考类似的问题，有助于你预处理数据，并使预测结果更准确。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stats of batch 1:\n",
      "Samples: 10000\n",
      "Label Counts: {0: 1005, 1: 974, 2: 1032, 3: 1016, 4: 999, 5: 937, 6: 1030, 7: 1001, 8: 1025, 9: 981}\n",
      "First 20 Labels: [6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6]\n",
      "\n",
      "Example of Image 5:\n",
      "Image - Min Value: 0 Max Value: 252\n",
      "Image - Shape: (32, 32, 3)\n",
      "Label - Label Id: 1 Name: automobile\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAH0CAYAAADVH+85AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x17934a14be0>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import helper\n",
    "import numpy as np\n",
    "\n",
    "# Explore the dataset\n",
    "batch_id = 1\n",
    "sample_id = 5\n",
    "helper.display_stats(cifar10_dataset_folder_path, batch_id, sample_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实现预处理函数\n",
    "\n",
    "### 标准化\n",
    "\n",
    "在下面的单元中，实现 `normalize` 函数，传入图片数据 `x`，并返回标准化 Numpy 数组。值应该在 0 到 1 的范围内（含 0 和 1）。返回对象应该和 `x` 的形状一样。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def normalize(x):\n",
    "    \"\"\"\n",
    "    Normalize a list of sample image data in the range of 0 to 1\n",
    "    : x: List of image data.  The image shape is (32, 32, 3)\n",
    "    : return: Numpy array of normalize data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return x / 255\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_normalize(normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot 编码\n",
    "\n",
    "和之前的代码单元一样，你将为预处理实现一个函数。这次，你将实现 `one_hot_encode` 函数。输入，也就是 `x`，是一个标签列表。实现该函数，以返回为 one_hot 编码的 Numpy 数组的标签列表。标签的可能值为 0 到 9。每次调用 `one_hot_encode` 时，对于每个值，one_hot 编码函数应该返回相同的编码。确保将编码映射保存到该函数外面。\n",
    "\n",
    "提示：不要重复发明轮子。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10]\n",
      "[ 0 10]\n",
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder()\n",
    "each_label = np.array(list(range(10))).reshape(-1,1)\n",
    "enc.fit(each_label)\n",
    "print(enc.n_values_)\n",
    "print(enc.feature_indices_)\n",
    "\n",
    "def one_hot_encode(x):\n",
    "    \"\"\"\n",
    "    One hot encode a list of sample labels. Return a one-hot encoded vector for each label.\n",
    "    : x: List of sample Labels\n",
    "    : return: Numpy array of one-hot encoded labels\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    X = np.array(x).reshape(-1, 1)\n",
    "    return enc.transform(X).toarray()\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_one_hot_encode(one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 随机化数据\n",
    "\n",
    "之前探索数据时，你已经了解到，样本的顺序是随机的。再随机化一次也不会有什么关系，但是对于这个数据集没有必要。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预处理所有数据并保存\n",
    "\n",
    "运行下方的代码单元，将预处理所有 CIFAR-10 数据，并保存到文件中。下面的代码还使用了 10% 的训练数据，用来验证。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "# Preprocess Training, Validation, and Testing Data\n",
    "helper.preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 检查点\n",
    "\n",
    "这是你的第一个检查点。如果你什么时候决定再回到该记事本，或需要重新启动该记事本，你可以从这里开始。预处理的数据已保存到本地。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import pickle\n",
    "import problem_unittests as tests\n",
    "import helper\n",
    "\n",
    "# Load the Preprocessed Validation data\n",
    "valid_features, valid_labels = pickle.load(open('preprocess_validation.p', mode='rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建网络\n",
    "\n",
    "对于该神经网络，你需要将每层都构建为一个函数。你看到的大部分代码都位于函数外面。要更全面地测试你的代码，我们需要你将每层放入一个函数中。这样使我们能够提供更好的反馈，并使用我们的统一测试检测简单的错误，然后再提交项目。\n",
    "\n",
    ">**注意**：如果你觉得每周很难抽出足够的时间学习这门课程，我们为此项目提供了一个小捷径。对于接下来的几个问题，你可以使用 [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) 程序包中的类来构建每个层级，但是“卷积和最大池化层级”部分的层级除外。TF Layers 和 Keras 及 TFLearn 层级类似，因此很容易学会。\n",
    "\n",
    ">但是，如果你想充分利用这门课程，请尝试自己解决所有问题，不使用 TF Layers 程序包中的任何类。你依然可以使用其他程序包中的类，这些类和你在 TF Layers 中的类名称是一样的！例如，你可以使用 TF Neural Network 版本的 `conv2d` 类 [tf.nn.conv2d](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d)，而不是 TF Layers 版本的 `conv2d` 类 [tf.layers.conv2d](https://www.tensorflow.org/api_docs/python/tf/layers/conv2d)。\n",
    "\n",
    "我们开始吧！\n",
    "\n",
    "\n",
    "### 输入\n",
    "\n",
    "神经网络需要读取图片数据、one-hot 编码标签和丢弃保留概率（dropout keep probability）。请实现以下函数：\n",
    "\n",
    "* 实现 `neural_net_image_input`\n",
    " * 返回 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * 使用 `image_shape` 设置形状，部分大小设为 `None`\n",
    " * 使用 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) 中的 TensorFlow `name` 参数对 TensorFlow 占位符 \"x\" 命名\n",
    "* 实现 `neural_net_label_input`\n",
    " * 返回 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * 使用 `n_classes` 设置形状，部分大小设为 `None`\n",
    " * 使用 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) 中的 TensorFlow `name` 参数对 TensorFlow 占位符 \"y\" 命名\n",
    "* 实现 `neural_net_keep_prob_input`\n",
    " * 返回 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)，用于丢弃保留概率\n",
    " * 使用 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) 中的 TensorFlow `name` 参数对 TensorFlow 占位符 \"keep_prob\" 命名\n",
    "\n",
    "这些名称将在项目结束时，用于加载保存的模型。\n",
    "\n",
    "注意：TensorFlow 中的 `None` 表示形状可以是动态大小。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Input Tests Passed.\n",
      "Label Input Tests Passed.\n",
      "Keep Prob Tests Passed.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def neural_net_image_input(image_shape):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of image input\n",
    "    : image_shape: Shape of the images\n",
    "    : return: Tensor for image input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32, shape=[None, image_shape[0], image_shape[1], image_shape[2]], name='x')\n",
    "\n",
    "\n",
    "def neural_net_label_input(n_classes):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of label input\n",
    "    : n_classes: Number of classes\n",
    "    : return: Tensor for label input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32, shape=[None, n_classes], name='y')\n",
    "\n",
    "\n",
    "def neural_net_keep_prob_input():\n",
    "    \"\"\"\n",
    "    Return a Tensor for keep probability\n",
    "    : return: Tensor for keep probability.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32, shape=None, name='keep_prob')\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tf.reset_default_graph()\n",
    "tests.test_nn_image_inputs(neural_net_image_input)\n",
    "tests.test_nn_label_inputs(neural_net_label_input)\n",
    "tests.test_nn_keep_prob_inputs(neural_net_keep_prob_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 卷积和最大池化层\n",
    "\n",
    "卷积层级适合处理图片。对于此代码单元，你应该实现函数 `conv2d_maxpool` 以便应用卷积然后进行最大池化：\n",
    "\n",
    "* 使用 `conv_ksize`、`conv_num_outputs` 和 `x_tensor` 的形状创建权重（weight）和偏置（bias）。\n",
    "* 使用权重和 `conv_strides` 对 `x_tensor` 应用卷积。\n",
    " * 建议使用我们建议的间距（padding），当然也可以使用任何其他间距。\n",
    "* 添加偏置\n",
    "* 向卷积中添加非线性激活（nonlinear activation）\n",
    "* 使用 `pool_ksize` 和 `pool_strides` 应用最大池化\n",
    " * 建议使用我们建议的间距（padding），当然也可以使用任何其他间距。\n",
    "\n",
    "**注意**：对于**此层**，**请勿使用** [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers)，但是仍然可以使用 TensorFlow 的 [Neural Network](https://www.tensorflow.org/api_docs/python/tf/nn) 包。对于所有**其他层**，你依然可以使用快捷方法。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides):\n",
    "    \"\"\"\n",
    "    Apply convolution then max pooling to x_tensor\n",
    "    :param x_tensor: TensorFlow Tensor\n",
    "    :param conv_num_outputs: Number of outputs for the convolutional layer\n",
    "    :param conv_ksize: kernal size 2-D Tuple for the convolutional layer\n",
    "    :param conv_strides: Stride 2-D Tuple for convolution\n",
    "    :param pool_ksize: kernal size 2-D Tuple for pool\n",
    "    :param pool_strides: Stride 2-D Tuple for pool\n",
    "    : return: A tensor that represents convolution and max pooling of x_tensor\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    weights = tf.Variable(tf.truncated_normal([conv_ksize[0], conv_ksize[1], x_tensor.get_shape().as_list()[-1], conv_num_outputs], stddev=0.1))\n",
    "    biases = tf.Variable(tf.zeros([conv_num_outputs]))\n",
    "    net = tf.nn.conv2d(x_tensor, weights, [1, conv_strides[0], conv_strides[1], 1], 'SAME')\n",
    "    net = tf.nn.bias_add(net, biases)\n",
    "    net = tf.nn.relu(net)\n",
    "\n",
    "    pool_kernel = [1, pool_ksize[0], pool_ksize[1], 1]\n",
    "    pool_strides = [1, pool_strides[0], pool_strides[1], 1]\n",
    "    net = tf.nn.max_pool(net, pool_kernel, pool_strides, 'VALID')\n",
    "\n",
    "    return net\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_con_pool(conv2d_maxpool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 扁平化层\n",
    "\n",
    "实现 `flatten` 函数，将 `x_tensor` 的维度从四维张量（4-D tensor）变成二维张量。输出应该是形状（*部分大小（Batch Size）*，*扁平化图片大小（Flattened Image Size）*）。快捷方法：对于此层，你可以使用 [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) 包中的类。如果你想要更大挑战，可以仅使用其他 TensorFlow 程序包。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def flatten(x_tensor):\n",
    "    \"\"\"\n",
    "    Flatten x_tensor to (Batch Size, Flattened Image Size)\n",
    "    : x_tensor: A tensor of size (Batch Size, ...), where ... are the image dimensions.\n",
    "    : return: A tensor of size (Batch Size, Flattened Image Size).\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    shape = x_tensor.get_shape().as_list()\n",
    "    dim = np.prod(shape[1:])\n",
    "    x_tensor = tf.reshape(x_tensor, [-1,dim])\n",
    "    return x_tensor\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_flatten(flatten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 全连接层\n",
    "\n",
    "实现 `fully_conn` 函数，以向 `x_tensor` 应用完全连接的层级，形状为（*部分大小（Batch Size）*，*num_outputs*）。快捷方法：对于此层，你可以使用 [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) 包中的类。如果你想要更大挑战，可以仅使用其他 TensorFlow 程序包。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def fully_conn(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a fully connected layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    weights = tf.Variable(tf.truncated_normal(shape=[x_tensor.get_shape().as_list()[-1], num_outputs], mean=0, stddev=1))\n",
    "    biases = tf.Variable(tf.zeros(shape=[num_outputs]))\n",
    "    net = tf.nn.bias_add(tf.matmul(x_tensor, weights), biases)\n",
    "    net = tf.nn.relu(net)\n",
    "    return net\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_fully_conn(fully_conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 输出层\n",
    "\n",
    "实现 `output` 函数，向 x_tensor 应用完全连接的层级，形状为（*部分大小（Batch Size）*，*num_outputs*）。快捷方法：对于此层，你可以使用 [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) 包中的类。如果你想要更大挑战，可以仅使用其他 TensorFlow 程序包。\n",
    "\n",
    "**注意**：该层级不应应用 Activation、softmax 或交叉熵（cross entropy）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def output(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a output layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    weights = tf.Variable(tf.truncated_normal(shape=[x_tensor.get_shape().as_list()[-1], num_outputs], mean=0, stddev=1))\n",
    "    biases = tf.Variable(tf.zeros(shape=[num_outputs]))\n",
    "    net = tf.nn.bias_add(tf.matmul(x_tensor, weights), biases)\n",
    "    return net\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_output(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建卷积模型\n",
    "\n",
    "实现函数 `conv_net`， 创建卷积神经网络模型。该函数传入一批图片 `x`，并输出对数（logits）。使用你在上方创建的层创建此模型：\n",
    "\n",
    "* 应用 1、2 或 3 个卷积和最大池化层（Convolution and Max Pool layers）\n",
    "* 应用一个扁平层（Flatten Layer）\n",
    "* 应用 1、2 或 3 个完全连接层（Fully Connected Layers）\n",
    "* 应用一个输出层（Output Layer）\n",
    "* 返回输出\n",
    "* 使用 `keep_prob` 向模型中的一个或多个层应用 [TensorFlow 的 Dropout](https://www.tensorflow.org/api_docs/python/tf/nn/dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Built!\n"
     ]
    }
   ],
   "source": [
    "def conv_net(x, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a convolutional neural network model\n",
    "    : x: Placeholder tensor that holds image data.\n",
    "    : keep_prob: Placeholder tensor that hold dropout keep probability.\n",
    "    : return: Tensor that represents logits\n",
    "    \"\"\"\n",
    "    # TODO: Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "    #    Play around with different number of outputs, kernel size and stride\n",
    "    # Function Definition from Above:\n",
    "    #    conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    \n",
    "#     net = conv2d_maxpool(x, 32, (5,5), (1,1), (2,2), (2,2))\n",
    "#     net = tf.nn.dropout(net, keep_prob)\n",
    "#     net = conv2d_maxpool(net, 32, (5,5), (1,1), (2,2), (2,2))\n",
    "#     net = conv2d_maxpool(net, 64, (5,5), (1,1), (2,2), (2,2))\n",
    "\n",
    "    net = conv2d_maxpool(x, 32, (3,3), (1,1), (2,2), (2,2))\n",
    "    net = tf.nn.dropout(net, keep_prob)\n",
    "    net = conv2d_maxpool(net, 64, (3,3), (1,1), (2,2), (2,2))\n",
    "    net = tf.nn.dropout(net, keep_prob)\n",
    "    net = conv2d_maxpool(net, 64, (3,3), (1,1), (2,2), (2,2))\n",
    "\n",
    "    # TODO: Apply a Flatten Layer\n",
    "    # Function Definition from Above:\n",
    "    #   flatten(x_tensor)\n",
    "    \n",
    "    net = flatten(net)\n",
    "\n",
    "    # TODO: Apply 1, 2, or 3 Fully Connected Layers\n",
    "    #    Play around with different number of outputs\n",
    "    # Function Definition from Above:\n",
    "    #   fully_conn(x_tensor, num_outputs)\n",
    "    \n",
    "    net = fully_conn(net, 64)\n",
    "    \n",
    "    # TODO: Apply an Output Layer\n",
    "    #    Set this to the number of classes\n",
    "    # Function Definition from Above:\n",
    "    #   output(x_tensor, num_outputs)\n",
    "    \n",
    "    net = output(net, enc.n_values_)\n",
    "    \n",
    "    # TODO: return output\n",
    "    return net\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "\n",
    "##############################\n",
    "## Build the Neural Network ##\n",
    "##############################\n",
    "\n",
    "# Remove previous weights, bias, inputs, etc..\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "x = neural_net_image_input((32, 32, 3))\n",
    "y = neural_net_label_input(10)\n",
    "keep_prob = neural_net_keep_prob_input()\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, keep_prob)\n",
    "\n",
    "# Name logits Tensor, so that is can be loaded from disk after training\n",
    "logits = tf.identity(logits, name='logits')\n",
    "\n",
    "# Loss and Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "\n",
    "tests.test_conv_net(conv_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练神经网络\n",
    "\n",
    "### 单次优化\n",
    "\n",
    "实现函数 `train_neural_network` 以进行单次优化（single optimization）。该优化应该使用 `optimizer` 优化 `session`，其中 `feed_dict` 具有以下参数：\n",
    "\n",
    "* `x` 表示图片输入\n",
    "* `y` 表示标签\n",
    "* `keep_prob` 表示丢弃的保留率\n",
    "\n",
    "每个部分都会调用该函数，所以 `tf.global_variables_initializer()` 已经被调用。\n",
    "\n",
    "注意：不需要返回任何内容。该函数只是用来优化神经网络。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def train_neural_network(session, optimizer, keep_probability, feature_batch, label_batch):\n",
    "    \"\"\"\n",
    "    Optimize the session on a batch of images and labels\n",
    "    : session: Current TensorFlow session\n",
    "    : optimizer: TensorFlow optimizer function\n",
    "    : keep_probability: keep probability\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    _ = session.run([optimizer, cost, accuracy], feed_dict={x: feature_batch, y: label_batch, keep_prob: keep_probability})\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_train_nn(train_neural_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 显示数据\n",
    "\n",
    "实现函数 `print_stats` 以输出损失和验证准确率。使用全局变量 `valid_features` 和 `valid_labels` 计算验证准确率。使用保留率 `1.0` 计算损失和验证准确率（loss and validation accuracy）。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
    "    \"\"\"\n",
    "    Print information about loss and validation accuracy\n",
    "    : session: Current TensorFlow session\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    : cost: TensorFlow cost function\n",
    "    : accuracy: TensorFlow accuracy function\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    valid_loss, valid_accuracy = session.run([cost, accuracy], feed_dict={x: valid_features, y: valid_labels, keep_prob: 1})\n",
    "    print(\"valid loss {:.3f}, accuracy {:.3f}\".format(valid_loss, valid_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 超参数\n",
    "\n",
    "调试以下超参数：\n",
    "* 设置 `epochs` 表示神经网络停止学习或开始过拟合的迭代次数\n",
    "* 设置 `batch_size`，表示机器内存允许的部分最大体积。大部分人设为以下常见内存大小：\n",
    "\n",
    " * 64\n",
    " * 128\n",
    " * 256\n",
    " * ...\n",
    "* 设置 `keep_probability` 表示使用丢弃时保留节点的概率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Tune Parameters\n",
    "epochs = 100\n",
    "batch_size = 256\n",
    "keep_probability = 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 在单个 CIFAR-10 部分上训练\n",
    "\n",
    "我们先用单个部分，而不是用所有的 CIFAR-10 批次训练神经网络。这样可以节省时间，并对模型进行迭代，以提高准确率。最终验证准确率达到 50% 或以上之后，在下一部分对所有数据运行模型。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the Training on a Single Batch...\n",
      "Epoch  1, CIFAR-10 Batch 1:  valid loss 3.076, accuracy 0.140\n",
      "Epoch  2, CIFAR-10 Batch 1:  valid loss 2.299, accuracy 0.147\n",
      "Epoch  3, CIFAR-10 Batch 1:  valid loss 2.281, accuracy 0.141\n",
      "Epoch  4, CIFAR-10 Batch 1:  valid loss 2.264, accuracy 0.151\n",
      "Epoch  5, CIFAR-10 Batch 1:  valid loss 2.257, accuracy 0.159\n",
      "Epoch  6, CIFAR-10 Batch 1:  valid loss 2.241, accuracy 0.176\n",
      "Epoch  7, CIFAR-10 Batch 1:  valid loss 2.221, accuracy 0.182\n",
      "Epoch  8, CIFAR-10 Batch 1:  valid loss 2.197, accuracy 0.187\n",
      "Epoch  9, CIFAR-10 Batch 1:  valid loss 2.160, accuracy 0.209\n",
      "Epoch 10, CIFAR-10 Batch 1:  valid loss 2.116, accuracy 0.219\n",
      "Epoch 11, CIFAR-10 Batch 1:  valid loss 2.067, accuracy 0.237\n",
      "Epoch 12, CIFAR-10 Batch 1:  valid loss 1.998, accuracy 0.264\n",
      "Epoch 13, CIFAR-10 Batch 1:  valid loss 2.000, accuracy 0.268\n",
      "Epoch 14, CIFAR-10 Batch 1:  valid loss 1.930, accuracy 0.292\n",
      "Epoch 15, CIFAR-10 Batch 1:  valid loss 1.890, accuracy 0.297\n",
      "Epoch 16, CIFAR-10 Batch 1:  valid loss 1.841, accuracy 0.318\n",
      "Epoch 17, CIFAR-10 Batch 1:  valid loss 1.789, accuracy 0.354\n",
      "Epoch 18, CIFAR-10 Batch 1:  valid loss 1.773, accuracy 0.344\n",
      "Epoch 19, CIFAR-10 Batch 1:  valid loss 1.754, accuracy 0.352\n",
      "Epoch 20, CIFAR-10 Batch 1:  valid loss 1.719, accuracy 0.372\n",
      "Epoch 21, CIFAR-10 Batch 1:  valid loss 1.695, accuracy 0.383\n",
      "Epoch 22, CIFAR-10 Batch 1:  valid loss 1.705, accuracy 0.377\n",
      "Epoch 23, CIFAR-10 Batch 1:  valid loss 1.664, accuracy 0.395\n",
      "Epoch 24, CIFAR-10 Batch 1:  valid loss 1.618, accuracy 0.413\n",
      "Epoch 25, CIFAR-10 Batch 1:  valid loss 1.606, accuracy 0.410\n",
      "Epoch 26, CIFAR-10 Batch 1:  valid loss 1.607, accuracy 0.411\n",
      "Epoch 27, CIFAR-10 Batch 1:  valid loss 1.575, accuracy 0.426\n",
      "Epoch 28, CIFAR-10 Batch 1:  valid loss 1.553, accuracy 0.435\n",
      "Epoch 29, CIFAR-10 Batch 1:  valid loss 1.545, accuracy 0.439\n",
      "Epoch 30, CIFAR-10 Batch 1:  valid loss 1.544, accuracy 0.438\n",
      "Epoch 31, CIFAR-10 Batch 1:  valid loss 1.501, accuracy 0.460\n",
      "Epoch 32, CIFAR-10 Batch 1:  valid loss 1.534, accuracy 0.444\n",
      "Epoch 33, CIFAR-10 Batch 1:  valid loss 1.478, accuracy 0.464\n",
      "Epoch 34, CIFAR-10 Batch 1:  valid loss 1.482, accuracy 0.459\n",
      "Epoch 35, CIFAR-10 Batch 1:  valid loss 1.525, accuracy 0.444\n",
      "Epoch 36, CIFAR-10 Batch 1:  valid loss 1.438, accuracy 0.481\n",
      "Epoch 37, CIFAR-10 Batch 1:  valid loss 1.451, accuracy 0.482\n",
      "Epoch 38, CIFAR-10 Batch 1:  valid loss 1.453, accuracy 0.472\n",
      "Epoch 39, CIFAR-10 Batch 1:  valid loss 1.420, accuracy 0.489\n",
      "Epoch 40, CIFAR-10 Batch 1:  valid loss 1.410, accuracy 0.490\n",
      "Epoch 41, CIFAR-10 Batch 1:  valid loss 1.417, accuracy 0.480\n",
      "Epoch 42, CIFAR-10 Batch 1:  valid loss 1.415, accuracy 0.484\n",
      "Epoch 43, CIFAR-10 Batch 1:  valid loss 1.391, accuracy 0.495\n",
      "Epoch 44, CIFAR-10 Batch 1:  valid loss 1.386, accuracy 0.502\n",
      "Epoch 45, CIFAR-10 Batch 1:  valid loss 1.433, accuracy 0.480\n",
      "Epoch 46, CIFAR-10 Batch 1:  valid loss 1.370, accuracy 0.503\n",
      "Epoch 47, CIFAR-10 Batch 1:  valid loss 1.369, accuracy 0.509\n",
      "Epoch 48, CIFAR-10 Batch 1:  valid loss 1.384, accuracy 0.502\n",
      "Epoch 49, CIFAR-10 Batch 1:  valid loss 1.366, accuracy 0.507\n",
      "Epoch 50, CIFAR-10 Batch 1:  valid loss 1.362, accuracy 0.508\n",
      "Epoch 51, CIFAR-10 Batch 1:  valid loss 1.335, accuracy 0.518\n",
      "Epoch 52, CIFAR-10 Batch 1:  valid loss 1.340, accuracy 0.516\n",
      "Epoch 53, CIFAR-10 Batch 1:  valid loss 1.370, accuracy 0.509\n",
      "Epoch 54, CIFAR-10 Batch 1:  valid loss 1.340, accuracy 0.518\n",
      "Epoch 55, CIFAR-10 Batch 1:  valid loss 1.341, accuracy 0.522\n",
      "Epoch 56, CIFAR-10 Batch 1:  valid loss 1.320, accuracy 0.525\n",
      "Epoch 57, CIFAR-10 Batch 1:  valid loss 1.327, accuracy 0.524\n",
      "Epoch 58, CIFAR-10 Batch 1:  valid loss 1.325, accuracy 0.524\n",
      "Epoch 59, CIFAR-10 Batch 1:  valid loss 1.402, accuracy 0.513\n",
      "Epoch 60, CIFAR-10 Batch 1:  valid loss 1.334, accuracy 0.522\n",
      "Epoch 61, CIFAR-10 Batch 1:  valid loss 1.301, accuracy 0.534\n",
      "Epoch 62, CIFAR-10 Batch 1:  valid loss 1.320, accuracy 0.528\n",
      "Epoch 63, CIFAR-10 Batch 1:  valid loss 1.288, accuracy 0.540\n",
      "Epoch 64, CIFAR-10 Batch 1:  valid loss 1.290, accuracy 0.546\n",
      "Epoch 65, CIFAR-10 Batch 1:  valid loss 1.268, accuracy 0.546\n",
      "Epoch 66, CIFAR-10 Batch 1:  valid loss 1.295, accuracy 0.549\n",
      "Epoch 67, CIFAR-10 Batch 1:  valid loss 1.297, accuracy 0.530\n",
      "Epoch 68, CIFAR-10 Batch 1:  valid loss 1.255, accuracy 0.545\n",
      "Epoch 69, CIFAR-10 Batch 1:  valid loss 1.318, accuracy 0.542\n",
      "Epoch 70, CIFAR-10 Batch 1:  valid loss 1.274, accuracy 0.544\n",
      "Epoch 71, CIFAR-10 Batch 1:  valid loss 1.281, accuracy 0.545\n",
      "Epoch 72, CIFAR-10 Batch 1:  valid loss 1.266, accuracy 0.548\n",
      "Epoch 73, CIFAR-10 Batch 1:  valid loss 1.239, accuracy 0.559\n",
      "Epoch 74, CIFAR-10 Batch 1:  valid loss 1.236, accuracy 0.560\n",
      "Epoch 75, CIFAR-10 Batch 1:  valid loss 1.223, accuracy 0.561\n",
      "Epoch 76, CIFAR-10 Batch 1:  valid loss 1.248, accuracy 0.558\n",
      "Epoch 77, CIFAR-10 Batch 1:  valid loss 1.234, accuracy 0.564\n",
      "Epoch 78, CIFAR-10 Batch 1:  valid loss 1.296, accuracy 0.546\n",
      "Epoch 79, CIFAR-10 Batch 1:  valid loss 1.263, accuracy 0.556\n",
      "Epoch 80, CIFAR-10 Batch 1:  valid loss 1.275, accuracy 0.554\n",
      "Epoch 81, CIFAR-10 Batch 1:  valid loss 1.264, accuracy 0.554\n",
      "Epoch 82, CIFAR-10 Batch 1:  valid loss 1.215, accuracy 0.570\n",
      "Epoch 83, CIFAR-10 Batch 1:  valid loss 1.235, accuracy 0.564\n",
      "Epoch 84, CIFAR-10 Batch 1:  valid loss 1.238, accuracy 0.567\n",
      "Epoch 85, CIFAR-10 Batch 1:  valid loss 1.244, accuracy 0.562\n",
      "Epoch 86, CIFAR-10 Batch 1:  valid loss 1.261, accuracy 0.563\n",
      "Epoch 87, CIFAR-10 Batch 1:  valid loss 1.234, accuracy 0.570\n",
      "Epoch 88, CIFAR-10 Batch 1:  valid loss 1.227, accuracy 0.573\n",
      "Epoch 89, CIFAR-10 Batch 1:  valid loss 1.265, accuracy 0.563\n",
      "Epoch 90, CIFAR-10 Batch 1:  valid loss 1.236, accuracy 0.563\n",
      "Epoch 91, CIFAR-10 Batch 1:  valid loss 1.257, accuracy 0.562\n",
      "Epoch 92, CIFAR-10 Batch 1:  valid loss 1.266, accuracy 0.560\n",
      "Epoch 93, CIFAR-10 Batch 1:  valid loss 1.236, accuracy 0.572\n",
      "Epoch 94, CIFAR-10 Batch 1:  valid loss 1.188, accuracy 0.588\n",
      "Epoch 95, CIFAR-10 Batch 1:  valid loss 1.209, accuracy 0.581\n",
      "Epoch 96, CIFAR-10 Batch 1:  valid loss 1.198, accuracy 0.583\n",
      "Epoch 97, CIFAR-10 Batch 1:  valid loss 1.213, accuracy 0.576\n",
      "Epoch 98, CIFAR-10 Batch 1:  valid loss 1.211, accuracy 0.579\n",
      "Epoch 99, CIFAR-10 Batch 1:  valid loss 1.188, accuracy 0.585\n",
      "Epoch 100, CIFAR-10 Batch 1:  valid loss 1.224, accuracy 0.579\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "print('Checking the Training on a Single Batch...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        batch_i = 1\n",
    "        for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "            train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "        print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "        print_stats(sess, batch_features, batch_labels, cost, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 完全训练模型\n",
    "\n",
    "现在，单个 CIFAR-10 部分的准确率已经不错了，试试所有五个部分吧。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch  1, CIFAR-10 Batch 1:  valid loss 2.709, accuracy 0.121\n",
      "Epoch  1, CIFAR-10 Batch 2:  valid loss 2.329, accuracy 0.136\n",
      "Epoch  1, CIFAR-10 Batch 3:  valid loss 2.276, accuracy 0.139\n",
      "Epoch  1, CIFAR-10 Batch 4:  valid loss 2.255, accuracy 0.157\n",
      "Epoch  1, CIFAR-10 Batch 5:  valid loss 2.228, accuracy 0.170\n",
      "Epoch  2, CIFAR-10 Batch 1:  valid loss 2.177, accuracy 0.202\n",
      "Epoch  2, CIFAR-10 Batch 2:  valid loss 2.132, accuracy 0.215\n",
      "Epoch  2, CIFAR-10 Batch 3:  valid loss 2.080, accuracy 0.235\n",
      "Epoch  2, CIFAR-10 Batch 4:  valid loss 2.015, accuracy 0.271\n",
      "Epoch  2, CIFAR-10 Batch 5:  valid loss 1.972, accuracy 0.287\n",
      "Epoch  3, CIFAR-10 Batch 1:  valid loss 1.882, accuracy 0.327\n",
      "Epoch  3, CIFAR-10 Batch 2:  valid loss 1.883, accuracy 0.321\n",
      "Epoch  3, CIFAR-10 Batch 3:  valid loss 1.829, accuracy 0.335\n",
      "Epoch  3, CIFAR-10 Batch 4:  valid loss 1.784, accuracy 0.357\n",
      "Epoch  3, CIFAR-10 Batch 5:  valid loss 1.785, accuracy 0.355\n",
      "Epoch  4, CIFAR-10 Batch 1:  valid loss 1.720, accuracy 0.386\n",
      "Epoch  4, CIFAR-10 Batch 2:  valid loss 1.771, accuracy 0.355\n",
      "Epoch  4, CIFAR-10 Batch 3:  valid loss 1.690, accuracy 0.380\n",
      "Epoch  4, CIFAR-10 Batch 4:  valid loss 1.648, accuracy 0.408\n",
      "Epoch  4, CIFAR-10 Batch 5:  valid loss 1.659, accuracy 0.398\n",
      "Epoch  5, CIFAR-10 Batch 1:  valid loss 1.630, accuracy 0.409\n",
      "Epoch  5, CIFAR-10 Batch 2:  valid loss 1.692, accuracy 0.375\n",
      "Epoch  5, CIFAR-10 Batch 3:  valid loss 1.601, accuracy 0.417\n",
      "Epoch  5, CIFAR-10 Batch 4:  valid loss 1.591, accuracy 0.413\n",
      "Epoch  5, CIFAR-10 Batch 5:  valid loss 1.591, accuracy 0.424\n",
      "Epoch  6, CIFAR-10 Batch 1:  valid loss 1.562, accuracy 0.432\n",
      "Epoch  6, CIFAR-10 Batch 2:  valid loss 1.565, accuracy 0.433\n",
      "Epoch  6, CIFAR-10 Batch 3:  valid loss 1.544, accuracy 0.439\n",
      "Epoch  6, CIFAR-10 Batch 4:  valid loss 1.518, accuracy 0.447\n",
      "Epoch  6, CIFAR-10 Batch 5:  valid loss 1.540, accuracy 0.439\n",
      "Epoch  7, CIFAR-10 Batch 1:  valid loss 1.508, accuracy 0.453\n",
      "Epoch  7, CIFAR-10 Batch 2:  valid loss 1.507, accuracy 0.455\n",
      "Epoch  7, CIFAR-10 Batch 3:  valid loss 1.526, accuracy 0.444\n",
      "Epoch  7, CIFAR-10 Batch 4:  valid loss 1.487, accuracy 0.454\n",
      "Epoch  7, CIFAR-10 Batch 5:  valid loss 1.548, accuracy 0.432\n",
      "Epoch  8, CIFAR-10 Batch 1:  valid loss 1.477, accuracy 0.460\n",
      "Epoch  8, CIFAR-10 Batch 2:  valid loss 1.479, accuracy 0.457\n",
      "Epoch  8, CIFAR-10 Batch 3:  valid loss 1.474, accuracy 0.461\n",
      "Epoch  8, CIFAR-10 Batch 4:  valid loss 1.421, accuracy 0.481\n",
      "Epoch  8, CIFAR-10 Batch 5:  valid loss 1.459, accuracy 0.465\n",
      "Epoch  9, CIFAR-10 Batch 1:  valid loss 1.464, accuracy 0.472\n",
      "Epoch  9, CIFAR-10 Batch 2:  valid loss 1.438, accuracy 0.478\n",
      "Epoch  9, CIFAR-10 Batch 3:  valid loss 1.454, accuracy 0.465\n",
      "Epoch  9, CIFAR-10 Batch 4:  valid loss 1.422, accuracy 0.478\n",
      "Epoch  9, CIFAR-10 Batch 5:  valid loss 1.453, accuracy 0.472\n",
      "Epoch 10, CIFAR-10 Batch 1:  valid loss 1.393, accuracy 0.499\n",
      "Epoch 10, CIFAR-10 Batch 2:  valid loss 1.414, accuracy 0.501\n",
      "Epoch 10, CIFAR-10 Batch 3:  valid loss 1.431, accuracy 0.468\n",
      "Epoch 10, CIFAR-10 Batch 4:  valid loss 1.387, accuracy 0.488\n",
      "Epoch 10, CIFAR-10 Batch 5:  valid loss 1.372, accuracy 0.496\n",
      "Epoch 11, CIFAR-10 Batch 1:  valid loss 1.398, accuracy 0.493\n",
      "Epoch 11, CIFAR-10 Batch 2:  valid loss 1.390, accuracy 0.496\n",
      "Epoch 11, CIFAR-10 Batch 3:  valid loss 1.352, accuracy 0.506\n",
      "Epoch 11, CIFAR-10 Batch 4:  valid loss 1.361, accuracy 0.501\n",
      "Epoch 11, CIFAR-10 Batch 5:  valid loss 1.349, accuracy 0.499\n",
      "Epoch 12, CIFAR-10 Batch 1:  valid loss 1.344, accuracy 0.511\n",
      "Epoch 12, CIFAR-10 Batch 2:  valid loss 1.326, accuracy 0.521\n",
      "Epoch 12, CIFAR-10 Batch 3:  valid loss 1.323, accuracy 0.520\n",
      "Epoch 12, CIFAR-10 Batch 4:  valid loss 1.353, accuracy 0.505\n",
      "Epoch 12, CIFAR-10 Batch 5:  valid loss 1.307, accuracy 0.526\n",
      "Epoch 13, CIFAR-10 Batch 1:  valid loss 1.309, accuracy 0.529\n",
      "Epoch 13, CIFAR-10 Batch 2:  valid loss 1.296, accuracy 0.532\n",
      "Epoch 13, CIFAR-10 Batch 3:  valid loss 1.306, accuracy 0.528\n",
      "Epoch 13, CIFAR-10 Batch 4:  valid loss 1.328, accuracy 0.517\n",
      "Epoch 13, CIFAR-10 Batch 5:  valid loss 1.283, accuracy 0.539\n",
      "Epoch 14, CIFAR-10 Batch 1:  valid loss 1.244, accuracy 0.555\n",
      "Epoch 14, CIFAR-10 Batch 2:  valid loss 1.350, accuracy 0.515\n",
      "Epoch 14, CIFAR-10 Batch 3:  valid loss 1.244, accuracy 0.548\n",
      "Epoch 14, CIFAR-10 Batch 4:  valid loss 1.279, accuracy 0.533\n",
      "Epoch 14, CIFAR-10 Batch 5:  valid loss 1.246, accuracy 0.549\n",
      "Epoch 15, CIFAR-10 Batch 1:  valid loss 1.253, accuracy 0.555\n",
      "Epoch 15, CIFAR-10 Batch 2:  valid loss 1.265, accuracy 0.539\n",
      "Epoch 15, CIFAR-10 Batch 3:  valid loss 1.215, accuracy 0.568\n",
      "Epoch 15, CIFAR-10 Batch 4:  valid loss 1.338, accuracy 0.511\n",
      "Epoch 15, CIFAR-10 Batch 5:  valid loss 1.202, accuracy 0.568\n",
      "Epoch 16, CIFAR-10 Batch 1:  valid loss 1.200, accuracy 0.572\n",
      "Epoch 16, CIFAR-10 Batch 2:  valid loss 1.243, accuracy 0.554\n",
      "Epoch 16, CIFAR-10 Batch 3:  valid loss 1.222, accuracy 0.561\n",
      "Epoch 16, CIFAR-10 Batch 4:  valid loss 1.253, accuracy 0.548\n",
      "Epoch 16, CIFAR-10 Batch 5:  valid loss 1.222, accuracy 0.557\n",
      "Epoch 17, CIFAR-10 Batch 1:  valid loss 1.202, accuracy 0.573\n",
      "Epoch 17, CIFAR-10 Batch 2:  valid loss 1.198, accuracy 0.569\n",
      "Epoch 17, CIFAR-10 Batch 3:  valid loss 1.188, accuracy 0.575\n",
      "Epoch 17, CIFAR-10 Batch 4:  valid loss 1.230, accuracy 0.561\n",
      "Epoch 17, CIFAR-10 Batch 5:  valid loss 1.161, accuracy 0.586\n",
      "Epoch 18, CIFAR-10 Batch 1:  valid loss 1.154, accuracy 0.595\n",
      "Epoch 18, CIFAR-10 Batch 2:  valid loss 1.211, accuracy 0.568\n",
      "Epoch 18, CIFAR-10 Batch 3:  valid loss 1.182, accuracy 0.578\n",
      "Epoch 18, CIFAR-10 Batch 4:  valid loss 1.192, accuracy 0.575\n",
      "Epoch 18, CIFAR-10 Batch 5:  valid loss 1.160, accuracy 0.588\n",
      "Epoch 19, CIFAR-10 Batch 1:  valid loss 1.212, accuracy 0.577\n",
      "Epoch 19, CIFAR-10 Batch 2:  valid loss 1.194, accuracy 0.574\n",
      "Epoch 19, CIFAR-10 Batch 3:  valid loss 1.171, accuracy 0.586\n",
      "Epoch 19, CIFAR-10 Batch 4:  valid loss 1.113, accuracy 0.611\n",
      "Epoch 19, CIFAR-10 Batch 5:  valid loss 1.148, accuracy 0.591\n",
      "Epoch 20, CIFAR-10 Batch 1:  valid loss 1.146, accuracy 0.592\n",
      "Epoch 20, CIFAR-10 Batch 2:  valid loss 1.157, accuracy 0.592\n",
      "Epoch 20, CIFAR-10 Batch 3:  valid loss 1.109, accuracy 0.606\n",
      "Epoch 20, CIFAR-10 Batch 4:  valid loss 1.135, accuracy 0.601\n",
      "Epoch 20, CIFAR-10 Batch 5:  valid loss 1.126, accuracy 0.598\n",
      "Epoch 21, CIFAR-10 Batch 1:  valid loss 1.141, accuracy 0.595\n",
      "Epoch 21, CIFAR-10 Batch 2:  valid loss 1.158, accuracy 0.584\n",
      "Epoch 21, CIFAR-10 Batch 3:  valid loss 1.113, accuracy 0.606\n",
      "Epoch 21, CIFAR-10 Batch 4:  valid loss 1.135, accuracy 0.597\n",
      "Epoch 21, CIFAR-10 Batch 5:  valid loss 1.084, accuracy 0.612\n",
      "Epoch 22, CIFAR-10 Batch 1:  valid loss 1.136, accuracy 0.608\n",
      "Epoch 22, CIFAR-10 Batch 2:  valid loss 1.130, accuracy 0.601\n",
      "Epoch 22, CIFAR-10 Batch 3:  valid loss 1.105, accuracy 0.613\n",
      "Epoch 22, CIFAR-10 Batch 4:  valid loss 1.169, accuracy 0.585\n",
      "Epoch 22, CIFAR-10 Batch 5:  valid loss 1.132, accuracy 0.594\n",
      "Epoch 23, CIFAR-10 Batch 1:  valid loss 1.122, accuracy 0.606\n",
      "Epoch 23, CIFAR-10 Batch 2:  valid loss 1.137, accuracy 0.596\n",
      "Epoch 23, CIFAR-10 Batch 3:  valid loss 1.041, accuracy 0.632\n",
      "Epoch 23, CIFAR-10 Batch 4:  valid loss 1.136, accuracy 0.596\n",
      "Epoch 23, CIFAR-10 Batch 5:  valid loss 1.056, accuracy 0.632\n",
      "Epoch 24, CIFAR-10 Batch 1:  valid loss 1.082, accuracy 0.622\n",
      "Epoch 24, CIFAR-10 Batch 2:  valid loss 1.082, accuracy 0.615\n",
      "Epoch 24, CIFAR-10 Batch 3:  valid loss 1.058, accuracy 0.630\n",
      "Epoch 24, CIFAR-10 Batch 4:  valid loss 1.096, accuracy 0.613\n",
      "Epoch 24, CIFAR-10 Batch 5:  valid loss 1.043, accuracy 0.634\n",
      "Epoch 25, CIFAR-10 Batch 1:  valid loss 1.047, accuracy 0.631\n",
      "Epoch 25, CIFAR-10 Batch 2:  valid loss 1.062, accuracy 0.628\n",
      "Epoch 25, CIFAR-10 Batch 3:  valid loss 1.048, accuracy 0.631\n",
      "Epoch 25, CIFAR-10 Batch 4:  valid loss 1.036, accuracy 0.630\n",
      "Epoch 25, CIFAR-10 Batch 5:  valid loss 1.049, accuracy 0.634\n",
      "Epoch 26, CIFAR-10 Batch 1:  valid loss 1.068, accuracy 0.625\n",
      "Epoch 26, CIFAR-10 Batch 2:  valid loss 1.087, accuracy 0.623\n",
      "Epoch 26, CIFAR-10 Batch 3:  valid loss 1.040, accuracy 0.637\n",
      "Epoch 26, CIFAR-10 Batch 4:  valid loss 1.025, accuracy 0.646\n",
      "Epoch 26, CIFAR-10 Batch 5:  valid loss 1.000, accuracy 0.645\n",
      "Epoch 27, CIFAR-10 Batch 1:  valid loss 1.013, accuracy 0.641\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27, CIFAR-10 Batch 2:  valid loss 1.048, accuracy 0.635\n",
      "Epoch 27, CIFAR-10 Batch 3:  valid loss 0.991, accuracy 0.651\n",
      "Epoch 27, CIFAR-10 Batch 4:  valid loss 1.009, accuracy 0.643\n",
      "Epoch 27, CIFAR-10 Batch 5:  valid loss 0.985, accuracy 0.650\n",
      "Epoch 28, CIFAR-10 Batch 1:  valid loss 1.023, accuracy 0.646\n",
      "Epoch 28, CIFAR-10 Batch 2:  valid loss 1.033, accuracy 0.644\n",
      "Epoch 28, CIFAR-10 Batch 3:  valid loss 0.970, accuracy 0.652\n",
      "Epoch 28, CIFAR-10 Batch 4:  valid loss 0.988, accuracy 0.653\n",
      "Epoch 28, CIFAR-10 Batch 5:  valid loss 0.980, accuracy 0.656\n",
      "Epoch 29, CIFAR-10 Batch 1:  valid loss 1.015, accuracy 0.650\n",
      "Epoch 29, CIFAR-10 Batch 2:  valid loss 1.072, accuracy 0.623\n",
      "Epoch 29, CIFAR-10 Batch 3:  valid loss 0.986, accuracy 0.650\n",
      "Epoch 29, CIFAR-10 Batch 4:  valid loss 1.004, accuracy 0.650\n",
      "Epoch 29, CIFAR-10 Batch 5:  valid loss 0.984, accuracy 0.659\n",
      "Epoch 30, CIFAR-10 Batch 1:  valid loss 0.983, accuracy 0.654\n",
      "Epoch 30, CIFAR-10 Batch 2:  valid loss 1.016, accuracy 0.645\n",
      "Epoch 30, CIFAR-10 Batch 3:  valid loss 0.952, accuracy 0.666\n",
      "Epoch 30, CIFAR-10 Batch 4:  valid loss 0.998, accuracy 0.646\n",
      "Epoch 30, CIFAR-10 Batch 5:  valid loss 0.983, accuracy 0.651\n",
      "Epoch 31, CIFAR-10 Batch 1:  valid loss 0.983, accuracy 0.657\n",
      "Epoch 31, CIFAR-10 Batch 2:  valid loss 1.055, accuracy 0.634\n",
      "Epoch 31, CIFAR-10 Batch 3:  valid loss 0.958, accuracy 0.661\n",
      "Epoch 31, CIFAR-10 Batch 4:  valid loss 0.965, accuracy 0.656\n",
      "Epoch 31, CIFAR-10 Batch 5:  valid loss 0.956, accuracy 0.664\n",
      "Epoch 32, CIFAR-10 Batch 1:  valid loss 0.969, accuracy 0.656\n",
      "Epoch 32, CIFAR-10 Batch 2:  valid loss 1.011, accuracy 0.649\n",
      "Epoch 32, CIFAR-10 Batch 3:  valid loss 0.939, accuracy 0.668\n",
      "Epoch 32, CIFAR-10 Batch 4:  valid loss 0.974, accuracy 0.656\n",
      "Epoch 32, CIFAR-10 Batch 5:  valid loss 0.938, accuracy 0.673\n",
      "Epoch 33, CIFAR-10 Batch 1:  valid loss 0.943, accuracy 0.669\n",
      "Epoch 33, CIFAR-10 Batch 2:  valid loss 0.969, accuracy 0.660\n",
      "Epoch 33, CIFAR-10 Batch 3:  valid loss 0.929, accuracy 0.669\n",
      "Epoch 33, CIFAR-10 Batch 4:  valid loss 0.957, accuracy 0.662\n",
      "Epoch 33, CIFAR-10 Batch 5:  valid loss 0.970, accuracy 0.658\n",
      "Epoch 34, CIFAR-10 Batch 1:  valid loss 0.931, accuracy 0.677\n",
      "Epoch 34, CIFAR-10 Batch 2:  valid loss 1.003, accuracy 0.648\n",
      "Epoch 34, CIFAR-10 Batch 3:  valid loss 0.934, accuracy 0.671\n",
      "Epoch 34, CIFAR-10 Batch 4:  valid loss 0.965, accuracy 0.659\n",
      "Epoch 34, CIFAR-10 Batch 5:  valid loss 0.927, accuracy 0.675\n",
      "Epoch 35, CIFAR-10 Batch 1:  valid loss 0.935, accuracy 0.673\n",
      "Epoch 35, CIFAR-10 Batch 2:  valid loss 0.958, accuracy 0.664\n",
      "Epoch 35, CIFAR-10 Batch 3:  valid loss 0.909, accuracy 0.679\n",
      "Epoch 35, CIFAR-10 Batch 4:  valid loss 0.939, accuracy 0.666\n",
      "Epoch 35, CIFAR-10 Batch 5:  valid loss 0.920, accuracy 0.679\n",
      "Epoch 36, CIFAR-10 Batch 1:  valid loss 0.925, accuracy 0.676\n",
      "Epoch 36, CIFAR-10 Batch 2:  valid loss 1.027, accuracy 0.639\n",
      "Epoch 36, CIFAR-10 Batch 3:  valid loss 0.932, accuracy 0.675\n",
      "Epoch 36, CIFAR-10 Batch 4:  valid loss 0.927, accuracy 0.671\n",
      "Epoch 36, CIFAR-10 Batch 5:  valid loss 0.960, accuracy 0.664\n",
      "Epoch 37, CIFAR-10 Batch 1:  valid loss 0.907, accuracy 0.687\n",
      "Epoch 37, CIFAR-10 Batch 2:  valid loss 1.035, accuracy 0.636\n",
      "Epoch 37, CIFAR-10 Batch 3:  valid loss 0.896, accuracy 0.688\n",
      "Epoch 37, CIFAR-10 Batch 4:  valid loss 0.932, accuracy 0.671\n",
      "Epoch 37, CIFAR-10 Batch 5:  valid loss 0.934, accuracy 0.670\n",
      "Epoch 38, CIFAR-10 Batch 1:  valid loss 0.930, accuracy 0.672\n",
      "Epoch 38, CIFAR-10 Batch 2:  valid loss 0.968, accuracy 0.661\n",
      "Epoch 38, CIFAR-10 Batch 3:  valid loss 0.890, accuracy 0.684\n",
      "Epoch 38, CIFAR-10 Batch 4:  valid loss 0.930, accuracy 0.677\n",
      "Epoch 38, CIFAR-10 Batch 5:  valid loss 0.983, accuracy 0.653\n",
      "Epoch 39, CIFAR-10 Batch 1:  valid loss 0.898, accuracy 0.686\n",
      "Epoch 39, CIFAR-10 Batch 2:  valid loss 0.965, accuracy 0.658\n",
      "Epoch 39, CIFAR-10 Batch 3:  valid loss 0.879, accuracy 0.692\n",
      "Epoch 39, CIFAR-10 Batch 4:  valid loss 0.935, accuracy 0.673\n",
      "Epoch 39, CIFAR-10 Batch 5:  valid loss 0.959, accuracy 0.669\n",
      "Epoch 40, CIFAR-10 Batch 1:  valid loss 0.880, accuracy 0.694\n",
      "Epoch 40, CIFAR-10 Batch 2:  valid loss 0.961, accuracy 0.668\n",
      "Epoch 40, CIFAR-10 Batch 3:  valid loss 0.877, accuracy 0.693\n",
      "Epoch 40, CIFAR-10 Batch 4:  valid loss 0.919, accuracy 0.683\n",
      "Epoch 40, CIFAR-10 Batch 5:  valid loss 0.976, accuracy 0.661\n",
      "Epoch 41, CIFAR-10 Batch 1:  valid loss 0.876, accuracy 0.699\n",
      "Epoch 41, CIFAR-10 Batch 2:  valid loss 0.995, accuracy 0.656\n",
      "Epoch 41, CIFAR-10 Batch 3:  valid loss 0.933, accuracy 0.679\n",
      "Epoch 41, CIFAR-10 Batch 4:  valid loss 0.939, accuracy 0.670\n",
      "Epoch 41, CIFAR-10 Batch 5:  valid loss 0.930, accuracy 0.675\n",
      "Epoch 42, CIFAR-10 Batch 1:  valid loss 0.891, accuracy 0.695\n",
      "Epoch 42, CIFAR-10 Batch 2:  valid loss 0.993, accuracy 0.660\n",
      "Epoch 42, CIFAR-10 Batch 3:  valid loss 0.853, accuracy 0.700\n",
      "Epoch 42, CIFAR-10 Batch 4:  valid loss 0.927, accuracy 0.682\n",
      "Epoch 42, CIFAR-10 Batch 5:  valid loss 0.873, accuracy 0.692\n",
      "Epoch 43, CIFAR-10 Batch 1:  valid loss 0.880, accuracy 0.696\n",
      "Epoch 43, CIFAR-10 Batch 2:  valid loss 0.941, accuracy 0.671\n",
      "Epoch 43, CIFAR-10 Batch 3:  valid loss 0.893, accuracy 0.691\n",
      "Epoch 43, CIFAR-10 Batch 4:  valid loss 0.896, accuracy 0.694\n",
      "Epoch 43, CIFAR-10 Batch 5:  valid loss 0.872, accuracy 0.700\n",
      "Epoch 44, CIFAR-10 Batch 1:  valid loss 0.870, accuracy 0.700\n",
      "Epoch 44, CIFAR-10 Batch 2:  valid loss 0.924, accuracy 0.685\n",
      "Epoch 44, CIFAR-10 Batch 3:  valid loss 0.876, accuracy 0.697\n",
      "Epoch 44, CIFAR-10 Batch 4:  valid loss 0.887, accuracy 0.692\n",
      "Epoch 44, CIFAR-10 Batch 5:  valid loss 0.917, accuracy 0.688\n",
      "Epoch 45, CIFAR-10 Batch 1:  valid loss 0.888, accuracy 0.692\n",
      "Epoch 45, CIFAR-10 Batch 2:  valid loss 0.945, accuracy 0.680\n",
      "Epoch 45, CIFAR-10 Batch 3:  valid loss 0.864, accuracy 0.701\n",
      "Epoch 45, CIFAR-10 Batch 4:  valid loss 0.947, accuracy 0.672\n",
      "Epoch 45, CIFAR-10 Batch 5:  valid loss 0.872, accuracy 0.698\n",
      "Epoch 46, CIFAR-10 Batch 1:  valid loss 0.845, accuracy 0.708\n",
      "Epoch 46, CIFAR-10 Batch 2:  valid loss 0.884, accuracy 0.692\n",
      "Epoch 46, CIFAR-10 Batch 3:  valid loss 0.854, accuracy 0.701\n",
      "Epoch 46, CIFAR-10 Batch 4:  valid loss 0.857, accuracy 0.701\n",
      "Epoch 46, CIFAR-10 Batch 5:  valid loss 0.905, accuracy 0.687\n",
      "Epoch 47, CIFAR-10 Batch 1:  valid loss 0.858, accuracy 0.710\n",
      "Epoch 47, CIFAR-10 Batch 2:  valid loss 0.932, accuracy 0.678\n",
      "Epoch 47, CIFAR-10 Batch 3:  valid loss 0.851, accuracy 0.706\n",
      "Epoch 47, CIFAR-10 Batch 4:  valid loss 0.935, accuracy 0.682\n",
      "Epoch 47, CIFAR-10 Batch 5:  valid loss 0.921, accuracy 0.683\n",
      "Epoch 48, CIFAR-10 Batch 1:  valid loss 0.850, accuracy 0.707\n",
      "Epoch 48, CIFAR-10 Batch 2:  valid loss 0.957, accuracy 0.667\n",
      "Epoch 48, CIFAR-10 Batch 3:  valid loss 0.851, accuracy 0.707\n",
      "Epoch 48, CIFAR-10 Batch 4:  valid loss 0.950, accuracy 0.673\n",
      "Epoch 48, CIFAR-10 Batch 5:  valid loss 0.906, accuracy 0.689\n",
      "Epoch 49, CIFAR-10 Batch 1:  valid loss 0.820, accuracy 0.716\n",
      "Epoch 49, CIFAR-10 Batch 2:  valid loss 0.938, accuracy 0.672\n",
      "Epoch 49, CIFAR-10 Batch 3:  valid loss 0.902, accuracy 0.694\n",
      "Epoch 49, CIFAR-10 Batch 4:  valid loss 0.921, accuracy 0.681\n",
      "Epoch 49, CIFAR-10 Batch 5:  valid loss 0.883, accuracy 0.696\n",
      "Epoch 50, CIFAR-10 Batch 1:  valid loss 0.847, accuracy 0.712\n",
      "Epoch 50, CIFAR-10 Batch 2:  valid loss 0.932, accuracy 0.678\n",
      "Epoch 50, CIFAR-10 Batch 3:  valid loss 0.895, accuracy 0.700\n",
      "Epoch 50, CIFAR-10 Batch 4:  valid loss 0.979, accuracy 0.665\n",
      "Epoch 50, CIFAR-10 Batch 5:  valid loss 0.978, accuracy 0.664\n",
      "Epoch 51, CIFAR-10 Batch 1:  valid loss 0.850, accuracy 0.706\n",
      "Epoch 51, CIFAR-10 Batch 2:  valid loss 0.909, accuracy 0.685\n",
      "Epoch 51, CIFAR-10 Batch 3:  valid loss 0.879, accuracy 0.702\n",
      "Epoch 51, CIFAR-10 Batch 4:  valid loss 0.893, accuracy 0.690\n",
      "Epoch 51, CIFAR-10 Batch 5:  valid loss 0.869, accuracy 0.697\n",
      "Epoch 52, CIFAR-10 Batch 1:  valid loss 0.839, accuracy 0.710\n",
      "Epoch 52, CIFAR-10 Batch 2:  valid loss 0.871, accuracy 0.701\n",
      "Epoch 52, CIFAR-10 Batch 3:  valid loss 0.843, accuracy 0.711\n",
      "Epoch 52, CIFAR-10 Batch 4:  valid loss 0.880, accuracy 0.693\n",
      "Epoch 52, CIFAR-10 Batch 5:  valid loss 0.849, accuracy 0.707\n",
      "Epoch 53, CIFAR-10 Batch 1:  valid loss 0.842, accuracy 0.709\n",
      "Epoch 53, CIFAR-10 Batch 2:  valid loss 0.898, accuracy 0.693\n",
      "Epoch 53, CIFAR-10 Batch 3:  valid loss 0.852, accuracy 0.713\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53, CIFAR-10 Batch 4:  valid loss 0.935, accuracy 0.674\n",
      "Epoch 53, CIFAR-10 Batch 5:  valid loss 0.856, accuracy 0.706\n",
      "Epoch 54, CIFAR-10 Batch 1:  valid loss 0.813, accuracy 0.720\n",
      "Epoch 54, CIFAR-10 Batch 2:  valid loss 0.841, accuracy 0.710\n",
      "Epoch 54, CIFAR-10 Batch 3:  valid loss 0.874, accuracy 0.697\n",
      "Epoch 54, CIFAR-10 Batch 4:  valid loss 0.843, accuracy 0.706\n",
      "Epoch 54, CIFAR-10 Batch 5:  valid loss 0.888, accuracy 0.694\n",
      "Epoch 55, CIFAR-10 Batch 1:  valid loss 0.823, accuracy 0.713\n",
      "Epoch 55, CIFAR-10 Batch 2:  valid loss 0.835, accuracy 0.715\n",
      "Epoch 55, CIFAR-10 Batch 3:  valid loss 0.873, accuracy 0.702\n",
      "Epoch 55, CIFAR-10 Batch 4:  valid loss 0.856, accuracy 0.700\n",
      "Epoch 55, CIFAR-10 Batch 5:  valid loss 0.826, accuracy 0.713\n",
      "Epoch 56, CIFAR-10 Batch 1:  valid loss 0.809, accuracy 0.723\n",
      "Epoch 56, CIFAR-10 Batch 2:  valid loss 0.840, accuracy 0.708\n",
      "Epoch 56, CIFAR-10 Batch 3:  valid loss 0.853, accuracy 0.710\n",
      "Epoch 56, CIFAR-10 Batch 4:  valid loss 0.857, accuracy 0.696\n",
      "Epoch 56, CIFAR-10 Batch 5:  valid loss 0.859, accuracy 0.708\n",
      "Epoch 57, CIFAR-10 Batch 1:  valid loss 0.803, accuracy 0.723\n",
      "Epoch 57, CIFAR-10 Batch 2:  valid loss 0.848, accuracy 0.709\n",
      "Epoch 57, CIFAR-10 Batch 3:  valid loss 0.862, accuracy 0.704\n",
      "Epoch 57, CIFAR-10 Batch 4:  valid loss 0.856, accuracy 0.705\n",
      "Epoch 57, CIFAR-10 Batch 5:  valid loss 0.862, accuracy 0.704\n",
      "Epoch 58, CIFAR-10 Batch 1:  valid loss 0.813, accuracy 0.718\n",
      "Epoch 58, CIFAR-10 Batch 2:  valid loss 0.838, accuracy 0.714\n",
      "Epoch 58, CIFAR-10 Batch 3:  valid loss 0.808, accuracy 0.718\n",
      "Epoch 58, CIFAR-10 Batch 4:  valid loss 0.879, accuracy 0.698\n",
      "Epoch 58, CIFAR-10 Batch 5:  valid loss 0.838, accuracy 0.712\n",
      "Epoch 59, CIFAR-10 Batch 1:  valid loss 0.810, accuracy 0.719\n",
      "Epoch 59, CIFAR-10 Batch 2:  valid loss 0.834, accuracy 0.713\n",
      "Epoch 59, CIFAR-10 Batch 3:  valid loss 0.831, accuracy 0.706\n",
      "Epoch 59, CIFAR-10 Batch 4:  valid loss 0.832, accuracy 0.709\n",
      "Epoch 59, CIFAR-10 Batch 5:  valid loss 0.872, accuracy 0.701\n",
      "Epoch 60, CIFAR-10 Batch 1:  valid loss 0.797, accuracy 0.728\n",
      "Epoch 60, CIFAR-10 Batch 2:  valid loss 0.836, accuracy 0.713\n",
      "Epoch 60, CIFAR-10 Batch 3:  valid loss 0.860, accuracy 0.702\n",
      "Epoch 60, CIFAR-10 Batch 4:  valid loss 0.885, accuracy 0.700\n",
      "Epoch 60, CIFAR-10 Batch 5:  valid loss 0.854, accuracy 0.706\n",
      "Epoch 61, CIFAR-10 Batch 1:  valid loss 0.806, accuracy 0.724\n",
      "Epoch 61, CIFAR-10 Batch 2:  valid loss 0.875, accuracy 0.700\n",
      "Epoch 61, CIFAR-10 Batch 3:  valid loss 0.836, accuracy 0.715\n",
      "Epoch 61, CIFAR-10 Batch 4:  valid loss 0.827, accuracy 0.720\n",
      "Epoch 61, CIFAR-10 Batch 5:  valid loss 0.849, accuracy 0.712\n",
      "Epoch 62, CIFAR-10 Batch 1:  valid loss 0.808, accuracy 0.725\n",
      "Epoch 62, CIFAR-10 Batch 2:  valid loss 0.830, accuracy 0.712\n",
      "Epoch 62, CIFAR-10 Batch 3:  valid loss 0.853, accuracy 0.706\n",
      "Epoch 62, CIFAR-10 Batch 4:  valid loss 0.827, accuracy 0.712\n",
      "Epoch 62, CIFAR-10 Batch 5:  valid loss 0.847, accuracy 0.715\n",
      "Epoch 63, CIFAR-10 Batch 1:  valid loss 0.814, accuracy 0.722\n",
      "Epoch 63, CIFAR-10 Batch 2:  valid loss 0.873, accuracy 0.699\n",
      "Epoch 63, CIFAR-10 Batch 3:  valid loss 0.825, accuracy 0.716\n",
      "Epoch 63, CIFAR-10 Batch 4:  valid loss 0.844, accuracy 0.707\n",
      "Epoch 63, CIFAR-10 Batch 5:  valid loss 0.829, accuracy 0.716\n",
      "Epoch 64, CIFAR-10 Batch 1:  valid loss 0.852, accuracy 0.706\n",
      "Epoch 64, CIFAR-10 Batch 2:  valid loss 0.830, accuracy 0.708\n",
      "Epoch 64, CIFAR-10 Batch 3:  valid loss 0.815, accuracy 0.714\n",
      "Epoch 64, CIFAR-10 Batch 4:  valid loss 0.826, accuracy 0.713\n",
      "Epoch 64, CIFAR-10 Batch 5:  valid loss 0.797, accuracy 0.727\n",
      "Epoch 65, CIFAR-10 Batch 1:  valid loss 0.800, accuracy 0.724\n",
      "Epoch 65, CIFAR-10 Batch 2:  valid loss 0.833, accuracy 0.707\n",
      "Epoch 65, CIFAR-10 Batch 3:  valid loss 0.853, accuracy 0.705\n",
      "Epoch 65, CIFAR-10 Batch 4:  valid loss 0.846, accuracy 0.706\n",
      "Epoch 65, CIFAR-10 Batch 5:  valid loss 0.872, accuracy 0.704\n",
      "Epoch 66, CIFAR-10 Batch 1:  valid loss 0.797, accuracy 0.724\n",
      "Epoch 66, CIFAR-10 Batch 2:  valid loss 0.889, accuracy 0.692\n",
      "Epoch 66, CIFAR-10 Batch 3:  valid loss 0.819, accuracy 0.719\n",
      "Epoch 66, CIFAR-10 Batch 4:  valid loss 0.829, accuracy 0.716\n",
      "Epoch 66, CIFAR-10 Batch 5:  valid loss 0.840, accuracy 0.718\n",
      "Epoch 67, CIFAR-10 Batch 1:  valid loss 0.783, accuracy 0.732\n",
      "Epoch 67, CIFAR-10 Batch 2:  valid loss 0.835, accuracy 0.713\n",
      "Epoch 67, CIFAR-10 Batch 3:  valid loss 0.809, accuracy 0.726\n",
      "Epoch 67, CIFAR-10 Batch 4:  valid loss 0.863, accuracy 0.701\n",
      "Epoch 67, CIFAR-10 Batch 5:  valid loss 0.829, accuracy 0.712\n",
      "Epoch 68, CIFAR-10 Batch 1:  valid loss 0.789, accuracy 0.727\n",
      "Epoch 68, CIFAR-10 Batch 2:  valid loss 0.861, accuracy 0.706\n",
      "Epoch 68, CIFAR-10 Batch 3:  valid loss 0.822, accuracy 0.721\n",
      "Epoch 68, CIFAR-10 Batch 4:  valid loss 0.868, accuracy 0.699\n",
      "Epoch 68, CIFAR-10 Batch 5:  valid loss 0.821, accuracy 0.715\n",
      "Epoch 69, CIFAR-10 Batch 1:  valid loss 0.815, accuracy 0.718\n",
      "Epoch 69, CIFAR-10 Batch 2:  valid loss 0.858, accuracy 0.704\n",
      "Epoch 69, CIFAR-10 Batch 3:  valid loss 0.823, accuracy 0.719\n",
      "Epoch 69, CIFAR-10 Batch 4:  valid loss 0.857, accuracy 0.710\n",
      "Epoch 69, CIFAR-10 Batch 5:  valid loss 0.856, accuracy 0.712\n",
      "Epoch 70, CIFAR-10 Batch 1:  valid loss 0.817, accuracy 0.721\n",
      "Epoch 70, CIFAR-10 Batch 2:  valid loss 0.841, accuracy 0.712\n",
      "Epoch 70, CIFAR-10 Batch 3:  valid loss 0.844, accuracy 0.715\n",
      "Epoch 70, CIFAR-10 Batch 4:  valid loss 0.833, accuracy 0.713\n",
      "Epoch 70, CIFAR-10 Batch 5:  valid loss 0.848, accuracy 0.709\n",
      "Epoch 71, CIFAR-10 Batch 1:  valid loss 0.795, accuracy 0.732\n",
      "Epoch 71, CIFAR-10 Batch 2:  valid loss 0.860, accuracy 0.702\n",
      "Epoch 71, CIFAR-10 Batch 3:  valid loss 0.960, accuracy 0.680\n",
      "Epoch 71, CIFAR-10 Batch 4:  valid loss 0.823, accuracy 0.718\n",
      "Epoch 71, CIFAR-10 Batch 5:  valid loss 0.812, accuracy 0.724\n",
      "Epoch 72, CIFAR-10 Batch 1:  valid loss 0.784, accuracy 0.736\n",
      "Epoch 72, CIFAR-10 Batch 2:  valid loss 0.860, accuracy 0.704\n",
      "Epoch 72, CIFAR-10 Batch 3:  valid loss 0.848, accuracy 0.713\n",
      "Epoch 72, CIFAR-10 Batch 4:  valid loss 0.857, accuracy 0.706\n",
      "Epoch 72, CIFAR-10 Batch 5:  valid loss 0.812, accuracy 0.724\n",
      "Epoch 73, CIFAR-10 Batch 1:  valid loss 0.814, accuracy 0.727\n",
      "Epoch 73, CIFAR-10 Batch 2:  valid loss 0.844, accuracy 0.715\n",
      "Epoch 73, CIFAR-10 Batch 3:  valid loss 0.849, accuracy 0.717\n",
      "Epoch 73, CIFAR-10 Batch 4:  valid loss 0.816, accuracy 0.722\n",
      "Epoch 73, CIFAR-10 Batch 5:  valid loss 0.815, accuracy 0.724\n",
      "Epoch 74, CIFAR-10 Batch 1:  valid loss 0.797, accuracy 0.729\n",
      "Epoch 74, CIFAR-10 Batch 2:  valid loss 0.825, accuracy 0.716\n",
      "Epoch 74, CIFAR-10 Batch 3:  valid loss 0.869, accuracy 0.706\n",
      "Epoch 74, CIFAR-10 Batch 4:  valid loss 0.827, accuracy 0.715\n",
      "Epoch 74, CIFAR-10 Batch 5:  valid loss 0.832, accuracy 0.721\n",
      "Epoch 75, CIFAR-10 Batch 1:  valid loss 0.777, accuracy 0.738\n",
      "Epoch 75, CIFAR-10 Batch 2:  valid loss 0.883, accuracy 0.700\n",
      "Epoch 75, CIFAR-10 Batch 3:  valid loss 0.862, accuracy 0.711\n",
      "Epoch 75, CIFAR-10 Batch 4:  valid loss 0.803, accuracy 0.720\n",
      "Epoch 75, CIFAR-10 Batch 5:  valid loss 0.815, accuracy 0.722\n",
      "Epoch 76, CIFAR-10 Batch 1:  valid loss 0.799, accuracy 0.730\n",
      "Epoch 76, CIFAR-10 Batch 2:  valid loss 0.839, accuracy 0.715\n",
      "Epoch 76, CIFAR-10 Batch 3:  valid loss 0.819, accuracy 0.725\n",
      "Epoch 76, CIFAR-10 Batch 4:  valid loss 0.851, accuracy 0.710\n",
      "Epoch 76, CIFAR-10 Batch 5:  valid loss 0.823, accuracy 0.724\n",
      "Epoch 77, CIFAR-10 Batch 1:  valid loss 0.804, accuracy 0.724\n",
      "Epoch 77, CIFAR-10 Batch 2:  valid loss 0.903, accuracy 0.698\n",
      "Epoch 77, CIFAR-10 Batch 3:  valid loss 0.837, accuracy 0.716\n",
      "Epoch 77, CIFAR-10 Batch 4:  valid loss 0.898, accuracy 0.696\n",
      "Epoch 77, CIFAR-10 Batch 5:  valid loss 0.792, accuracy 0.729\n",
      "Epoch 78, CIFAR-10 Batch 1:  valid loss 0.775, accuracy 0.734\n",
      "Epoch 78, CIFAR-10 Batch 2:  valid loss 0.870, accuracy 0.706\n",
      "Epoch 78, CIFAR-10 Batch 3:  valid loss 0.829, accuracy 0.716\n",
      "Epoch 78, CIFAR-10 Batch 4:  valid loss 0.834, accuracy 0.721\n",
      "Epoch 78, CIFAR-10 Batch 5:  valid loss 0.804, accuracy 0.732\n",
      "Epoch 79, CIFAR-10 Batch 1:  valid loss 0.784, accuracy 0.739\n",
      "Epoch 79, CIFAR-10 Batch 2:  valid loss 0.842, accuracy 0.715\n",
      "Epoch 79, CIFAR-10 Batch 3:  valid loss 0.845, accuracy 0.722\n",
      "Epoch 79, CIFAR-10 Batch 4:  valid loss 0.807, accuracy 0.726\n",
      "Epoch 79, CIFAR-10 Batch 5:  valid loss 0.785, accuracy 0.735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80, CIFAR-10 Batch 1:  valid loss 0.783, accuracy 0.740\n",
      "Epoch 80, CIFAR-10 Batch 2:  valid loss 0.833, accuracy 0.716\n",
      "Epoch 80, CIFAR-10 Batch 3:  valid loss 0.847, accuracy 0.720\n",
      "Epoch 80, CIFAR-10 Batch 4:  valid loss 0.796, accuracy 0.727\n",
      "Epoch 80, CIFAR-10 Batch 5:  valid loss 0.785, accuracy 0.732\n",
      "Epoch 81, CIFAR-10 Batch 1:  valid loss 0.774, accuracy 0.745\n",
      "Epoch 81, CIFAR-10 Batch 2:  valid loss 0.816, accuracy 0.725\n",
      "Epoch 81, CIFAR-10 Batch 3:  valid loss 0.839, accuracy 0.723\n",
      "Epoch 81, CIFAR-10 Batch 4:  valid loss 0.788, accuracy 0.734\n",
      "Epoch 81, CIFAR-10 Batch 5:  valid loss 0.821, accuracy 0.725\n",
      "Epoch 82, CIFAR-10 Batch 1:  valid loss 0.795, accuracy 0.735\n",
      "Epoch 82, CIFAR-10 Batch 2:  valid loss 0.871, accuracy 0.705\n",
      "Epoch 82, CIFAR-10 Batch 3:  valid loss 0.850, accuracy 0.719\n",
      "Epoch 82, CIFAR-10 Batch 4:  valid loss 0.838, accuracy 0.719\n",
      "Epoch 82, CIFAR-10 Batch 5:  valid loss 0.828, accuracy 0.721\n",
      "Epoch 83, CIFAR-10 Batch 1:  valid loss 0.792, accuracy 0.737\n",
      "Epoch 83, CIFAR-10 Batch 2:  valid loss 0.847, accuracy 0.713\n",
      "Epoch 83, CIFAR-10 Batch 3:  valid loss 0.842, accuracy 0.721\n",
      "Epoch 83, CIFAR-10 Batch 4:  valid loss 0.788, accuracy 0.733\n",
      "Epoch 83, CIFAR-10 Batch 5:  valid loss 0.806, accuracy 0.728\n",
      "Epoch 84, CIFAR-10 Batch 1:  valid loss 0.796, accuracy 0.733\n",
      "Epoch 84, CIFAR-10 Batch 2:  valid loss 0.823, accuracy 0.724\n",
      "Epoch 84, CIFAR-10 Batch 3:  valid loss 0.825, accuracy 0.727\n",
      "Epoch 84, CIFAR-10 Batch 4:  valid loss 0.796, accuracy 0.733\n",
      "Epoch 84, CIFAR-10 Batch 5:  valid loss 0.844, accuracy 0.718\n",
      "Epoch 85, CIFAR-10 Batch 1:  valid loss 0.776, accuracy 0.744\n",
      "Epoch 85, CIFAR-10 Batch 2:  valid loss 0.837, accuracy 0.716\n",
      "Epoch 85, CIFAR-10 Batch 3:  valid loss 0.859, accuracy 0.720\n",
      "Epoch 85, CIFAR-10 Batch 4:  valid loss 0.799, accuracy 0.730\n",
      "Epoch 85, CIFAR-10 Batch 5:  valid loss 0.848, accuracy 0.719\n",
      "Epoch 86, CIFAR-10 Batch 1:  valid loss 0.784, accuracy 0.737\n",
      "Epoch 86, CIFAR-10 Batch 2:  valid loss 0.866, accuracy 0.712\n",
      "Epoch 86, CIFAR-10 Batch 3:  valid loss 0.851, accuracy 0.721\n",
      "Epoch 86, CIFAR-10 Batch 4:  valid loss 0.834, accuracy 0.717\n",
      "Epoch 86, CIFAR-10 Batch 5:  valid loss 0.822, accuracy 0.727\n",
      "Epoch 87, CIFAR-10 Batch 1:  valid loss 0.784, accuracy 0.736\n",
      "Epoch 87, CIFAR-10 Batch 2:  valid loss 0.852, accuracy 0.717\n",
      "Epoch 87, CIFAR-10 Batch 3:  valid loss 0.818, accuracy 0.731\n",
      "Epoch 87, CIFAR-10 Batch 4:  valid loss 0.812, accuracy 0.726\n",
      "Epoch 87, CIFAR-10 Batch 5:  valid loss 0.818, accuracy 0.728\n",
      "Epoch 88, CIFAR-10 Batch 1:  valid loss 0.781, accuracy 0.746\n",
      "Epoch 88, CIFAR-10 Batch 2:  valid loss 0.813, accuracy 0.728\n",
      "Epoch 88, CIFAR-10 Batch 3:  valid loss 0.875, accuracy 0.716\n",
      "Epoch 88, CIFAR-10 Batch 4:  valid loss 0.826, accuracy 0.723\n",
      "Epoch 88, CIFAR-10 Batch 5:  valid loss 0.808, accuracy 0.734\n",
      "Epoch 89, CIFAR-10 Batch 1:  valid loss 0.803, accuracy 0.732\n",
      "Epoch 89, CIFAR-10 Batch 2:  valid loss 0.860, accuracy 0.716\n",
      "Epoch 89, CIFAR-10 Batch 3:  valid loss 0.830, accuracy 0.725\n",
      "Epoch 89, CIFAR-10 Batch 4:  valid loss 0.795, accuracy 0.735\n",
      "Epoch 89, CIFAR-10 Batch 5:  valid loss 0.855, accuracy 0.719\n",
      "Epoch 90, CIFAR-10 Batch 1:  valid loss 0.778, accuracy 0.742\n",
      "Epoch 90, CIFAR-10 Batch 2:  valid loss 0.849, accuracy 0.720\n",
      "Epoch 90, CIFAR-10 Batch 3:  valid loss 0.893, accuracy 0.708\n",
      "Epoch 90, CIFAR-10 Batch 4:  valid loss 0.834, accuracy 0.723\n",
      "Epoch 90, CIFAR-10 Batch 5:  valid loss 0.794, accuracy 0.740\n",
      "Epoch 91, CIFAR-10 Batch 1:  valid loss 0.775, accuracy 0.744\n",
      "Epoch 91, CIFAR-10 Batch 2:  valid loss 0.839, accuracy 0.724\n",
      "Epoch 91, CIFAR-10 Batch 3:  valid loss 0.882, accuracy 0.709\n",
      "Epoch 91, CIFAR-10 Batch 4:  valid loss 0.814, accuracy 0.726\n",
      "Epoch 91, CIFAR-10 Batch 5:  valid loss 0.821, accuracy 0.732\n",
      "Epoch 92, CIFAR-10 Batch 1:  valid loss 0.779, accuracy 0.742\n",
      "Epoch 92, CIFAR-10 Batch 2:  valid loss 0.889, accuracy 0.703\n",
      "Epoch 92, CIFAR-10 Batch 3:  valid loss 0.838, accuracy 0.727\n",
      "Epoch 92, CIFAR-10 Batch 4:  valid loss 0.781, accuracy 0.739\n",
      "Epoch 92, CIFAR-10 Batch 5:  valid loss 0.829, accuracy 0.729\n",
      "Epoch 93, CIFAR-10 Batch 1:  valid loss 0.786, accuracy 0.743\n",
      "Epoch 93, CIFAR-10 Batch 2:  valid loss 0.905, accuracy 0.703\n",
      "Epoch 93, CIFAR-10 Batch 3:  valid loss 0.868, accuracy 0.717\n",
      "Epoch 93, CIFAR-10 Batch 4:  valid loss 0.781, accuracy 0.735\n",
      "Epoch 93, CIFAR-10 Batch 5:  valid loss 0.825, accuracy 0.730\n",
      "Epoch 94, CIFAR-10 Batch 1:  valid loss 0.787, accuracy 0.742\n",
      "Epoch 94, CIFAR-10 Batch 2:  valid loss 0.944, accuracy 0.694\n",
      "Epoch 94, CIFAR-10 Batch 3:  valid loss 0.882, accuracy 0.717\n",
      "Epoch 94, CIFAR-10 Batch 4:  valid loss 0.803, accuracy 0.734\n",
      "Epoch 94, CIFAR-10 Batch 5:  valid loss 0.810, accuracy 0.734\n",
      "Epoch 95, CIFAR-10 Batch 1:  valid loss 0.788, accuracy 0.741\n",
      "Epoch 95, CIFAR-10 Batch 2:  valid loss 0.937, accuracy 0.690\n",
      "Epoch 95, CIFAR-10 Batch 3:  valid loss 0.868, accuracy 0.719\n",
      "Epoch 95, CIFAR-10 Batch 4:  valid loss 0.806, accuracy 0.739\n",
      "Epoch 95, CIFAR-10 Batch 5:  valid loss 0.823, accuracy 0.733\n",
      "Epoch 96, CIFAR-10 Batch 1:  valid loss 0.796, accuracy 0.736\n",
      "Epoch 96, CIFAR-10 Batch 2:  valid loss 0.840, accuracy 0.722\n",
      "Epoch 96, CIFAR-10 Batch 3:  valid loss 0.866, accuracy 0.719\n",
      "Epoch 96, CIFAR-10 Batch 4:  valid loss 0.811, accuracy 0.728\n",
      "Epoch 96, CIFAR-10 Batch 5:  valid loss 0.805, accuracy 0.735\n",
      "Epoch 97, CIFAR-10 Batch 1:  valid loss 0.797, accuracy 0.739\n",
      "Epoch 97, CIFAR-10 Batch 2:  valid loss 0.884, accuracy 0.713\n",
      "Epoch 97, CIFAR-10 Batch 3:  valid loss 0.817, accuracy 0.733\n",
      "Epoch 97, CIFAR-10 Batch 4:  valid loss 0.817, accuracy 0.729\n",
      "Epoch 97, CIFAR-10 Batch 5:  valid loss 0.794, accuracy 0.743\n",
      "Epoch 98, CIFAR-10 Batch 1:  valid loss 0.774, accuracy 0.746\n",
      "Epoch 98, CIFAR-10 Batch 2:  valid loss 0.845, accuracy 0.724\n",
      "Epoch 98, CIFAR-10 Batch 3:  valid loss 0.838, accuracy 0.730\n",
      "Epoch 98, CIFAR-10 Batch 4:  valid loss 0.789, accuracy 0.735\n",
      "Epoch 98, CIFAR-10 Batch 5:  valid loss 0.830, accuracy 0.731\n",
      "Epoch 99, CIFAR-10 Batch 1:  valid loss 0.790, accuracy 0.743\n",
      "Epoch 99, CIFAR-10 Batch 2:  valid loss 0.875, accuracy 0.714\n",
      "Epoch 99, CIFAR-10 Batch 3:  valid loss 0.811, accuracy 0.734\n",
      "Epoch 99, CIFAR-10 Batch 4:  valid loss 0.792, accuracy 0.737\n",
      "Epoch 99, CIFAR-10 Batch 5:  valid loss 0.808, accuracy 0.734\n",
      "Epoch 100, CIFAR-10 Batch 1:  valid loss 0.813, accuracy 0.736\n",
      "Epoch 100, CIFAR-10 Batch 2:  valid loss 0.859, accuracy 0.720\n",
      "Epoch 100, CIFAR-10 Batch 3:  valid loss 0.777, accuracy 0.743\n",
      "Epoch 100, CIFAR-10 Batch 4:  valid loss 0.799, accuracy 0.738\n",
      "Epoch 100, CIFAR-10 Batch 5:  valid loss 0.819, accuracy 0.735\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "save_model_path = './image_classification'\n",
    "\n",
    "print('Training...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        # Loop over all batches\n",
    "        n_batches = 5\n",
    "        for batch_i in range(1, n_batches + 1):\n",
    "            for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "                train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "            print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "            print_stats(sess, batch_features, batch_labels, cost, accuracy)\n",
    "            \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 检查点\n",
    "\n",
    "模型已保存到本地。\n",
    "\n",
    "## 测试模型\n",
    "\n",
    "利用测试数据集测试你的模型。这将是最终的准确率。你的准确率应该高于 50%。如果没达到，请继续调整模型结构和参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./image_classification\n",
      "Testing Accuracy: 0.72919921875\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAscAAAJ/CAYAAACUb342AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nv5cAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x179317f8c18>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 319,
       "width": 355
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import helper\n",
    "import random\n",
    "\n",
    "# Set batch size if not already set\n",
    "try:\n",
    "    if batch_size:\n",
    "        pass\n",
    "except NameError:\n",
    "    batch_size = 64\n",
    "\n",
    "save_model_path = './image_classification'\n",
    "n_samples = 4\n",
    "top_n_predictions = 3\n",
    "\n",
    "def test_model():\n",
    "    \"\"\"\n",
    "    Test the saved model against the test dataset\n",
    "    \"\"\"\n",
    "\n",
    "    test_features, test_labels = pickle.load(open('preprocess_test.p', mode='rb'))\n",
    "    loaded_graph = tf.Graph()\n",
    "\n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        # Load model\n",
    "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "        loader.restore(sess, save_model_path)\n",
    "\n",
    "        # Get Tensors from loaded model\n",
    "        loaded_x = loaded_graph.get_tensor_by_name('x:0')\n",
    "        loaded_y = loaded_graph.get_tensor_by_name('y:0')\n",
    "        loaded_keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "        loaded_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "        loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
    "        \n",
    "        # Get accuracy in batches for memory limitations\n",
    "        test_batch_acc_total = 0\n",
    "        test_batch_count = 0\n",
    "        \n",
    "        for test_feature_batch, test_label_batch in helper.batch_features_labels(test_features, test_labels, batch_size):\n",
    "            test_batch_acc_total += sess.run(\n",
    "                loaded_acc,\n",
    "                feed_dict={loaded_x: test_feature_batch, loaded_y: test_label_batch, loaded_keep_prob: 1.0})\n",
    "            test_batch_count += 1\n",
    "\n",
    "        print('Testing Accuracy: {}\\n'.format(test_batch_acc_total/test_batch_count))\n",
    "\n",
    "        # Print Random Samples\n",
    "        random_test_features, random_test_labels = tuple(zip(*random.sample(list(zip(test_features, test_labels)), n_samples)))\n",
    "        random_test_predictions = sess.run(\n",
    "            tf.nn.top_k(tf.nn.softmax(loaded_logits), top_n_predictions),\n",
    "            feed_dict={loaded_x: random_test_features, loaded_y: random_test_labels, loaded_keep_prob: 1.0})\n",
    "        helper.display_image_predictions(random_test_features, random_test_labels, random_test_predictions)\n",
    "\n",
    "\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 为何准确率只有50-80%？\n",
    "\n",
    "你可能想问，为何准确率不能更高了？首先，对于简单的 CNN 网络来说，50% 已经不低了。纯粹猜测的准确率为10%。但是，你可能注意到有人的准确率[远远超过 80%](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#43494641522d3130)。这是因为我们还没有介绍所有的神经网络知识。我们还需要掌握一些其他技巧。\n",
    "\n",
    "## 提交项目\n",
    "\n",
    "提交项目时，确保先运行所有单元，然后再保存记事本。将 notebook 文件另存为“dlnd_image_classification.ipynb”，再在目录 \"File\" -> \"Download as\" 另存为 HTML 格式。请在提交的项目中包含 “helper.py” 和 “problem_unittests.py” 文件。\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
